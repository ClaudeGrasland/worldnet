[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "2  About",
    "section": "",
    "text": "About this site : nothing for the moment …"
  },
  {
    "objectID": "01-Mediacloud.html",
    "href": "01-Mediacloud.html",
    "title": "3  Mediacloud",
    "section": "",
    "text": "(tbd : presentation of the MediaCloud project)\nMediacloud can be freely used by researchers. All you have to do is to create an account at the following adress :\nhttps://explorer.mediacloud.org\nYou have different ways to get title of news. We will focus here on a simple example of data obtained through the mediacloud interface. We suppose that you want to extract news from the Tunisian newspapers speaking from Europe."
  },
  {
    "objectID": "01-Mediacloud.html#selection-of-media-with-source-manager",
    "href": "01-Mediacloud.html#selection-of-media-with-source-manager",
    "title": "3  Mediacloud",
    "section": "3.1 Selection of media with source manager",
    "text": "3.1 Selection of media with source manager\nWe use the application called Source Manager and we introduce a research by collection which is the most convenient to explore what is available in a country. In our example, the target country is Tunisia and we have three collections that are propsed :\n\n\n\n\n\nWe have selected the collection named “Tunisia National” because we are interested in the most important newspapers of the country.\n\n\n\n\n\nThe buble graphic on the right indicates immediately the media that has produced the highest number of news, but it is wise to explore in more details the list on the left which indicates for each media the statting date of data collection.\nWhen a media appears interesting, we click on its name to obtain a brief summary of the metadata. For example, in the case of L’économiste Maghrebin the metadata indicates :\n\n\n\n\n\nThe media looks promising, but before to go further, it can be better to have a look at the website of the media to have a more concrete idea of the content if we don’t know in advance what it is about in terms of content, what is the ideological orientation, etc.\n\n\n\n\n\nHere we can see that this is an ecnomic journal, published in french, with news organized in concentric geographic circles (Nation > Maghreb > Africa > World) which is precisely what we are looking for in the IMAGEUN project. We will further complete the informations about this, but before to do that we have to check in more details if the production of the media is regular through time with another tool offered by mediacloud, the explorer."
  },
  {
    "objectID": "01-Mediacloud.html#checking-the-stability-through-time",
    "href": "01-Mediacloud.html#checking-the-stability-through-time",
    "title": "3  Mediacloud",
    "section": "3.2 Checking the stability through time",
    "text": "3.2 Checking the stability through time\nWe have clicked on search in explorer on the metadata page of the Source Manager and obtain a news interfacce where we modify the date to cover the full period of collection of the media (or our period of interest). In the research field, we let the search term * which indicates a research on all news.\n\n\n\n\n\nBelow your request, you obtain a graphic entitled Attention Over Time with the distribution of the number of news published per day which help you to verify if the distribution of news is regular through time. You just have to modify the type of graphic in order to visualize Story Count and you can choose the time span you want (day, week or month) for the evaluation of the regularity of news flow. In our example, we notice that at daily level they are some brief period of break in 2019, but the flow is reasonnabely regular with approximatively 5 news per day at the beginning and 10 to 20 in the final period. We also notice a classical week cycle with a decrease of news published during the week-end.\n\n\n\n\n\nGoing down, you will find a news panel entitled Total Attention which gives you the total number of stories found. In our example, we have a total of 13626 stories produced by our media over the period."
  },
  {
    "objectID": "01-Mediacloud.html#selection-of-news-specifically-related-to-a-topic-option",
    "href": "01-Mediacloud.html#selection-of-news-specifically-related-to-a-topic-option",
    "title": "3  Mediacloud",
    "section": "3.3 Selection of news specifically related to a topic (option)",
    "text": "3.3 Selection of news specifically related to a topic (option)\nYou can eventually use Mediacloud to check the number of news produced about a specific topic, for example Europe or European Union or EU. The request shouldbe put in lower case with “” for compounds. Detailed explanation are available in the query guide.\n\n\n\n\n\nThis time you can use the graphic option Stories percentage rather than Story count if you want to viusalize the salience of the topic through time.\n\n\n\n\n\nIn our example, we have 369 news that appears to be related to our request about Europe or EU with a relatively regular pattern at month level of 1 to 3 % of news and exceptionaly 5 to 7 %."
  },
  {
    "objectID": "01-Mediacloud.html#download-and-storage-of-news",
    "href": "01-Mediacloud.html#download-and-storage-of-news",
    "title": "3  Mediacloud",
    "section": "3.4 Download and storage of news",
    "text": "3.4 Download and storage of news\nAccording to your selection (all news or a specific topic) you will download more or less title. Here, me make the choice to get all news, which means that we have to repeat the original request with *.\nFinally, by clicking on the button Download all story URLS, you can get a .csv file that you can easily load in your favorite programming language as we will see in the next section."
  },
  {
    "objectID": "02-Quanteda.html",
    "href": "02-Quanteda.html",
    "title": "4  Quanteda",
    "section": "",
    "text": "In the previous section (ref…) whe have obtained a .csv file of news collected from MediaCloud. We will try now to put this data in a standard form and we have chosen the format of the quanteda package as reference for data organization and storage.\nBut of course the researchers involved in the project can prefer to use other R packages like tm or tidytext. And they can also prefer to use another programming language for Python. It is the reason why we explain how to transform and export the data that has been prepared and harmonized with quanteda in various format like .csv or JSON."
  },
  {
    "objectID": "02-Quanteda.html#procédure-dimportation",
    "href": "02-Quanteda.html#procédure-dimportation",
    "title": "4  Quanteda",
    "section": "4.1 Procédure d’importation",
    "text": "4.1 Procédure d’importation\nWe detail here an example of importation with the example of the newspaper “L’économiste maghrebin”\n\n4.1.1 Importation of text to R\nThis step is not always obvious because many problems of encoding can appear that are more or less easy to solve. In principle , the data from Media Cloud are exported in standard UTF-8 but as we will see it is not necessary the case.\nWe try firstly to use the standard R function read.csv():\n\nstore <- \"corpus/TUN/\"\nmedia <- \"fr_TUN_ecomag\"\ntype <-\".csv\"\n\nfic <- paste(store,media,type,sep=\"\")\n\ndf<-read.csv(fic,\n             sep=\",\",\n             header=T,\n             encoding = \"UTF-8\",\n             stringsAsFactors = F)\nhead(df)\n\n  stories_id        publish_date\n1 1129295780 2019-01-02 03:42:46\n2 1129295771 2019-01-02 04:06:27\n3 1129295760 2019-01-02 06:05:08\n4 1129578051 2019-01-02 10:05:06\n5 1129461662 2019-01-02 07:52:36\n6 1129461636 2019-01-02 08:57:54\n                                                                            title\n1                 Les tarifs de l&#8217;ADSL réduits à partir du 1er janvier 2019\n2                                   6ème Sfax Marathon International des Oliviers\n3                        Télécharger la version finale de la Loi de finances 2019\n4 Chawki Tabib : 245 dossiers de corruption présumée transmis au ministère public\n5                       Panoro Energy finalise l&#8217;acquisition de OMV Tunisia\n6              La partie syndicale maintient le boycott des examens du secondaire\n                                                                                                        url\n1                       https://www.leconomistemaghrebin.com/2019/01/02/tarifs-adsl-reduits-1-janvier-2019/\n2                     https://www.leconomistemaghrebin.com/2019/01/02/sfax-marathon-international-oliviers/\n3 https://www.leconomistemaghrebin.com/2019/01/02/telecharger-la-version-finale-de-la-loi-de-finances-2019/\n4 https://www.leconomistemaghrebin.com/2019/01/02/chawki-tabib-245-dossiers-transferes-au-ministere-public/\n5       https://www.leconomistemaghrebin.com/2019/01/02/panoro-energy-finalise-lacquisition-de-omv-tunisia/\n6              https://www.leconomistemaghrebin.com/2019/01/02/partie-syndicale-boycott-examens-secondaire/\n  language ap_syndicated themes media_id             media_name\n1       fr         False          623820 L'Economiste Maghrebin\n2       fr         False          623820 L'Economiste Maghrebin\n3       en         False          623820 L'Economiste Maghrebin\n4       fr         False          623820 L'Economiste Maghrebin\n5       fr         False          623820 L'Economiste Maghrebin\n6       fr         False          623820 L'Economiste Maghrebin\n                             media_url\n1 http://www.leconomistemaghrebin.com/\n2 http://www.leconomistemaghrebin.com/\n3 http://www.leconomistemaghrebin.com/\n4 http://www.leconomistemaghrebin.com/\n5 http://www.leconomistemaghrebin.com/\n6 http://www.leconomistemaghrebin.com/\n\nstr(df)\n\n'data.frame':   12794 obs. of  10 variables:\n $ stories_id   : int  1129295780 1129295771 1129295760 1129578051 1129461662 1129461636 1130259352 1131673651 1132241460 1132432991 ...\n $ publish_date : chr  \"2019-01-02 03:42:46\" \"2019-01-02 04:06:27\" \"2019-01-02 06:05:08\" \"2019-01-02 10:05:06\" ...\n $ title        : chr  \"Les tarifs de l&#8217;ADSL réduits à partir du 1er janvier 2019\" \"6ème Sfax Marathon International des Oliviers\" \"Télécharger la version finale de la Loi de finances 2019\" \"Chawki Tabib : 245 dossiers de corruption présumée transmis au ministère public\" ...\n $ url          : chr  \"https://www.leconomistemaghrebin.com/2019/01/02/tarifs-adsl-reduits-1-janvier-2019/\" \"https://www.leconomistemaghrebin.com/2019/01/02/sfax-marathon-international-oliviers/\" \"https://www.leconomistemaghrebin.com/2019/01/02/telecharger-la-version-finale-de-la-loi-de-finances-2019/\" \"https://www.leconomistemaghrebin.com/2019/01/02/chawki-tabib-245-dossiers-transferes-au-ministere-public/\" ...\n $ language     : chr  \"fr\" \"fr\" \"en\" \"fr\" ...\n $ ap_syndicated: chr  \"False\" \"False\" \"False\" \"False\" ...\n $ themes       : chr  \"\" \"\" \"\" \"\" ...\n $ media_id     : int  623820 623820 623820 623820 623820 623820 623820 623820 623820 623820 ...\n $ media_name   : chr  \"L'Economiste Maghrebin\" \"L'Economiste Maghrebin\" \"L'Economiste Maghrebin\" \"L'Economiste Maghrebin\" ...\n $ media_url    : chr  \"http://www.leconomistemaghrebin.com/\" \"http://www.leconomistemaghrebin.com/\" \"http://www.leconomistemaghrebin.com/\" \"http://www.leconomistemaghrebin.com/\" ...\n\n\nThe importation was successfull for 13623 news but message of errors appeared for 3 news where R sent a message of error telling :\nError in gregexpr(calltext, singleline, fixed = TRUE) : regular expression is invalid UTF-8\nLooking in more details, we discover also some problems of encoding in news like in the following example where the text of the news appears differently if we apply the standard functions paste() o0 the specialized function r knitr::kable for printing.\n\npaste(df[9, 3])\n\n[1] \"Néji Jalloul : &#8220;Nidaa Tounes peut revenir si&#8230;&#8221;\"\n\nkable((df[9,3]))\n\n\n\n\nx\n\n\n\n\nNéji Jalloul : “Nidaa Tounes peut revenir si…”\n\n\n\n\n\n\n\n4.1.2 encoding problems\nIt is sometime possible to adapt manually the encoding problem whan they are not too much as in present example.\n\ndf$text<-df$title\n# standardize apostrophe\ndf$text<-gsub(\"&#8217;\",\"'\",df$text)\n\n# standardize punct\ndf$text<-gsub('&#8230;','.',df$text)\n\n# standardize hyphens\ndf$text<-gsub('&#8211;','-',df$text)\n\n# Remove quotation marks\ndf$text<-gsub('&#171;&#160;','',df$text)\ndf$text<-gsub('&#160;&#187;','',df$text)\ndf$text<-gsub('&#8220;','',df$text)\ndf$text<-gsub('&#8221;','',df$text)\ndf$text<-gsub('&#8216;','',df$text)\ndf$text<-gsub('&#8243;','',df$text)\n\nWe can introduce othr cleaning procedures here or keep it for later analysis\n\n\n4.1.3 Transformation in quanteda format\nWe propose a storage based on quanteda format by just transforming the data that has been produced by readtext. We keep only the name of the source and the date of publication.\n\n# Create Quanteda corpus\nqd<-corpus(df,docid_field = \"stories_id\")\n\n\n# Select docvar fields and rename media\nqd$date <-as.Date(qd$publish_date)\nqd$source <-media\ndocvars(qd)<-docvars(qd)[,c(\"source\",\"date\")]\n\n\n\n\n# Add global meta\nmeta(qd,\"meta_source\")<-\"Media Cloud \"\nmeta(qd,\"meta_time\")<-\"Download the 2021-09-30\"\nmeta(qd,\"meta_author\")<-\"Elaborated by Claude Grasland\"\nmeta(qd,\"project\")<-\"ANR-DFG Project IMAGEUN\"\n\nWe have created a quanteda object with a lot of information stored in various fields. The structure of the object is the following one\n\nstr(qd)\n\n 'corpus' Named chr [1:12794] \"Les tarifs de l'ADSL réduits à partir du 1er janvier 2019\" ...\n - attr(*, \"names\")= chr [1:12794] \"1129295780\" \"1129295771\" \"1129295760\" \"1129578051\" ...\n - attr(*, \"docvars\")='data.frame': 12794 obs. of  5 variables:\n  ..$ docname_: chr [1:12794] \"1129295780\" \"1129295771\" \"1129295760\" \"1129578051\" ...\n  ..$ docid_  : Factor w/ 12794 levels \"1129295780\",\"1129295771\",..: 1 2 3 4 5 6 7 8 9 10 ...\n  ..$ segid_  : int [1:12794] 1 1 1 1 1 1 1 1 1 1 ...\n  ..$ source  : chr [1:12794] \"fr_TUN_ecomag\" \"fr_TUN_ecomag\" \"fr_TUN_ecomag\" \"fr_TUN_ecomag\" ...\n  ..$ date    : Date[1:12794], format: \"2019-01-02\" \"2019-01-02\" ...\n - attr(*, \"meta\")=List of 3\n  ..$ system:List of 6\n  .. ..$ package-version:Classes 'package_version', 'numeric_version'  hidden list of 1\n  .. .. ..$ : int [1:3] 3 2 4\n  .. ..$ r-version      :Classes 'R_system_version', 'package_version', 'numeric_version'  hidden list of 1\n  .. .. ..$ : int [1:3] 4 2 2\n  .. ..$ system         : Named chr [1:3] \"Darwin\" \"arm64\" \"claudegrasland1\"\n  .. .. ..- attr(*, \"names\")= chr [1:3] \"sysname\" \"machine\" \"user\"\n  .. ..$ directory      : chr \"/Users/claudegrasland1/git/worldnet\"\n  .. ..$ created        : Date[1:1], format: \"2023-03-22\"\n  .. ..$ source         : chr \"data.frame\"\n  ..$ object:List of 2\n  .. ..$ unit   : chr \"documents\"\n  .. ..$ summary:List of 2\n  .. .. ..$ hash: chr(0) \n  .. .. ..$ data: NULL\n  ..$ user  :List of 4\n  .. ..$ meta_source: chr \"Media Cloud \"\n  .. ..$ meta_time  : chr \"Download the 2021-09-30\"\n  .. ..$ meta_author: chr \"Elaborated by Claude Grasland\"\n  .. ..$ project    : chr \"ANR-DFG Project IMAGEUN\"\n\n\nWe can look at the first titles with head()\n\nkable(head(qd,3))\n\n\n\n\n\nx\n\n\n\n\n1129295780\nLes tarifs de l’ADSL réduits à partir du 1er janvier 2019\n\n\n1129295771\n6ème Sfax Marathon International des Oliviers\n\n\n1129295760\nTélécharger la version finale de la Loi de finances 2019\n\n\n\n\n\nWe can get meta information on each stories with summary()\n\nsummary(head(qd,3))\n\nCorpus consisting of 3 documents, showing 3 documents:\n\n       Text Types Tokens Sentences        source       date\n 1129295780    11     11         1 fr_TUN_ecomag 2019-01-02\n 1129295771     6      6         1 fr_TUN_ecomag 2019-01-02\n 1129295760     8     10         1 fr_TUN_ecomag 2019-01-02\n\n\nWe can get meta information about the full document\n\nmeta(qd)\n\n$meta_source\n[1] \"Media Cloud \"\n\n$meta_time\n[1] \"Download the 2021-09-30\"\n\n$meta_author\n[1] \"Elaborated by Claude Grasland\"\n\n$project\n[1] \"ANR-DFG Project IMAGEUN\"\n\n\n\n\n4.1.4 Storage of the quanteda object\nWe can finally save the object in .RDS format in a directory dedicated to our quanteda files. It can be usefull to give some information in the name of the file\n\nstore <- \"quanteda/\"\ntype<- \".RDS\"\nmyfile <- paste(store,media,type,sep=\"\")\nmyfile\n\n[1] \"quanteda/fr_TUN_ecomag.RDS\"\n\nsaveRDS(qd,myfile)\nqd[1:3]\n\nCorpus consisting of 3 documents and 2 docvars.\n1129295780 :\n\"Les tarifs de l'ADSL réduits à partir du 1er janvier 2019\"\n\n1129295771 :\n\"6ème Sfax Marathon International des Oliviers\"\n\n1129295760 :\n\"Télécharger la version finale de la Loi de finances 2019\"\n\nsummary(qd,3)\n\nCorpus consisting of 12794 documents, showing 3 documents:\n\n       Text Types Tokens Sentences        source       date\n 1129295780    11     11         1 fr_TUN_ecomag 2019-01-02\n 1129295771     6      6         1 fr_TUN_ecomag 2019-01-02\n 1129295760     8     10         1 fr_TUN_ecomag 2019-01-02\n\n\nWe have kept all the information present in the initial file, but also added specific metadata of interest for us. The size of the storage is now equal to 0.6 Mb which means a division by 6 as compared to the initial .csv file downloaded from Media Cloud.\n\n\n4.1.5 Backtransformation of quanteda to data.table or tibble\nIn the following steps, we will make an intensive use of quanteda, but sometimes it can be usefull to export the results in a more practical format or to use other packages. For this reasons, it is important to know that the tidytextpackage can easily transform quanteda object in tibbles which are more classical and easy to manage\n\ntd <- tidy(qd)\nhead(td)\n\n# A tibble: 6 × 3\n  text                                                         source date      \n  <chr>                                                        <chr>  <date>    \n1 Les tarifs de l'ADSL réduits à partir du 1er janvier 2019    fr_TU… 2019-01-02\n2 6ème Sfax Marathon International des Oliviers                fr_TU… 2019-01-02\n3 Télécharger la version finale de la Loi de finances 2019     fr_TU… 2019-01-02\n4 Chawki Tabib : 245 dossiers de corruption présumée transmis… fr_TU… 2019-01-02\n5 Panoro Energy finalise l'acquisition de OMV Tunisia          fr_TU… 2019-01-02\n6 La partie syndicale maintient le boycott des examens du sec… fr_TU… 2019-01-02\n\nstr(td)\n\ntibble [12,794 × 3] (S3: tbl_df/tbl/data.frame)\n $ text  : chr [1:12794] \"Les tarifs de l'ADSL réduits à partir du 1er janvier 2019\" \"6ème Sfax Marathon International des Oliviers\" \"Télécharger la version finale de la Loi de finances 2019\" \"Chawki Tabib : 245 dossiers de corruption présumée transmis au ministère public\" ...\n $ source: chr [1:12794] \"fr_TUN_ecomag\" \"fr_TUN_ecomag\" \"fr_TUN_ecomag\" \"fr_TUN_ecomag\" ...\n $ date  : Date[1:12794], format: \"2019-01-02\" \"2019-01-02\" ..."
  },
  {
    "objectID": "02-Quanteda.html#corpus",
    "href": "02-Quanteda.html#corpus",
    "title": "4  Quanteda",
    "section": "4.2 Corpus",
    "text": "4.2 Corpus\n\n4.2.1 Germany\n\n4.2.1.1 Frankfurter Allgemeine Zeitung\n\n\nCorpus consisting of 88313 documents, showing 3 documents:\n\n       Text Types Tokens Sentences        source       date\n  930016745     5      5         1 de_DEU_frankf 2020-09-06\n 1118202030    10     10         1 de_DEU_frankf 2021-07-06\n 1128764967    14     14         1 de_DEU_frankf 2019-01-01\n\n\n[1] \"Bundestagswahl: Durchmarsch der AfD\"                                                         \n[2] \"Kahl folgt auf Schindler: CSU kritisiert Wechsel an BND-Spitze\"                              \n[3] \"Dramatisches Ende einer Bergtour: Drei Deutsche nach eisiger Nacht in Tiroler Alpen gerettet\"\n[4] \"Trotz Gelbwesten-Protesten: Macron kündigt für 2019 weitere Reformen an\"                     \n[5] \"May wirbt in Neujahrsansprache für Brexit-Abkommen\"                                          \n\n\n\n\n4.2.1.2 Süddeutsche Zeitung\n\n\nCorpus consisting of 35444 documents, showing 5 documents:\n\n       Text Types Tokens Sentences        source       date\n  931884497     4      4         1 de_DEU_suddeu 2019-06-17\n 1128842071     8      8         1 de_DEU_suddeu 2019-01-01\n 1128842047     8      8         1 de_DEU_suddeu 2019-01-01\n 1128842007     4      4         1 de_DEU_suddeu 2019-01-01\n 1128842024     5      5         1 de_DEU_suddeu 2019-01-01\n\n\n[1] \"EU setzt Russland Ultimatum\"                                   \n[2] \"Flüchtlinge : Großbritannien verlegt Schiffe in den Ärmelkanal\"\n[3] \"Zugang zum Internet : Buena Vista Netz Club\"                   \n[4] \"Brasilien: Bolsonaros Plan\"                                    \n[5] \"Dirty Dancing: Getanzter Dreck\"                                \n\n\n\n\n\n4.2.2 France\n\n4.2.2.1 Le Figaro\n\n\nCorpus consisting of 128807 documents, showing 5 documents:\n\n       Text Types Tokens Sentences        source       date\n 1128863317    12     12         1 fr_FRA_figaro 2019-01-01\n 1128915698    11     11         1 fr_FRA_figaro 2019-01-01\n 1128915693     8      8         1 fr_FRA_figaro 2019-01-01\n 1128915594     8      8         1 fr_FRA_figaro 2019-01-01\n 1128915683     8      8         1 fr_FRA_figaro 2019-01-01\n\n\n[1] \"Légion d'honneur : autant de femmes distinguées que d'hommes ce 1er janvier\"\n[2] \"Tokyo : une voiture fonce dans la foule, 9 blessés\"                         \n[3] \"Thaïlande : le roi sera couronné en mai\"                                    \n[4] \"Ces joueurs qui pourraient enflammer le mercato hivernal\"                   \n[5] \"Strasbourg : 9 blessés à cause des pétards\"                                 \n\n\n\n\n4.2.2.2 Le Monde\n\n\nCorpus consisting of 49731 documents, showing 5 documents:\n\n       Text Types Tokens Sentences        source       date\n 1128825289    12     12         1 fr_FRA_lmonde 2019-01-01\n 1128864671    11     11         1 fr_FRA_lmonde 2019-01-01\n 1128864634     9      9         1 fr_FRA_lmonde 2019-01-01\n 1128864655    13     13         1 fr_FRA_lmonde 2019-01-01\n 1128908122    11     11         1 fr_FRA_lmonde 2019-01-01\n\n\n[1] \"Les pesticides de synthèse interdits aux particuliers à partir du 1er janvier\" \n[2] \"Mauritanie : un député antiesclavagiste libéré après cinq mois de prison\"      \n[3] \"Jeanne Calment était-elle vraiment la doyenne de l’humanité ?\"                 \n[4] \"Italie : après l’adoption du budget, 2019 commence dans une ambiance chaotique\"\n[5] \"Pérou : destitution de deux procureurs qui enquêtaient sur l’affaire Odebrecht\"\n\n\n\n\n\n4.2.3 Royaume-Uni\n\n4.2.3.1 The Guardian\n\n\nCorpus consisting of 77875 documents, showing 5 documents:\n\n       Text Types Tokens Sentences        source       date\n 1128777161    12     12         1 en_GBR_guardi 2019-01-01\n 1128777148    10     10         1 en_GBR_guardi 2019-01-01\n 1128795880    11     11         1 en_GBR_guardi 2019-01-01\n 1128795872     9      9         1 en_GBR_guardi 2019-01-01\n 1128795860    12     13         1 en_GBR_guardi 2019-01-01\n\n\n[1] \"Toxic legacy taints ANC as it nears 25-year rule in South Africa\"     \n[2] \"Why Trump’s Middle East peace plan is just a sideshow\"                \n[3] \"Preparations for the Harbin ice and snow festival – in pictures\"      \n[4] \"Turning air into drinking water: Africa's inspired inventors\"         \n[5] \"'Resign from Facebook': experts offer Mark Zuckerberg advice for 2019\"\n\n\n\n\n4.2.3.2 The Daily Telegraph\n\n\nCorpus consisting of 41803 documents, showing 5 documents:\n\n       Text Types Tokens Sentences        source       date\n 1001621055    10     13         2 en_GBR_telegr 2020-03-15\n  794012047     6      7         1 en_GBR_telegr 2021-04-15\n 1020025042    11     11         1 en_GBR_telegr 2020-07-06\n 1071998286     7      7         1 en_GBR_telegr 2021-06-26\n 1080057597    11     12         1 en_GBR_telegr 2020-06-15\n\n\n[1] \"Guant?namo 'suicides' were at secret 'black' site\"                             \n[2] \"IKEA founder 'was Nazi recruiter'\"                                             \n[3] \"Europe tells Britain to justify itself over fingerprinting children in schools\"\n[4] \"Sumo champion Asashoryu outrages sport with celebration\"                       \n[5] \"Barack Obama meets Jewish leaders over 'tough line' on Israel\"                 \n\n\n\n\n\n4.2.4 Ireland\n\n4.2.4.1 The Irish Time\n\n\nCorpus consisting of 108479 documents, showing 5 documents:\n\n       Text Types Tokens Sentences        source       date\n 1003842232     8      9         1 en_IRL_irtime 2020-01-15\n 1128791232     8      8         1 en_IRL_irtime 2019-01-01\n 1128791226     7      7         1 en_IRL_irtime 2019-01-01\n 1128803852    10     10         1 en_IRL_irtime 2019-01-01\n 1128874798    11     11         1 en_IRL_irtime 2019-01-01\n\n\n[1] \"Strong corporate tax receipts ‘sustainable’ until 2020\"      \n[2] \"Number of British people becoming Irish citizens surges\"     \n[3] \"7 tips to build your physical stamina\"                       \n[4] \"Having a baby abroad changed my perspective on living away\"  \n[5] \"New Year’s Eve celebrations around the world to ring in 2019\"\n\n\n\n\n4.2.4.2 The Belfast Telegraph\n\n\nCorpus consisting of 99932 documents, showing 5 documents:\n\n       Text Types Tokens Sentences        source       date\n 1128845104     8      8         1 en_NIR_beltel 2019-01-01\n 1128845083    11     11         1 en_NIR_beltel 2019-01-01\n 1128845064     9      9         1 en_NIR_beltel 2019-01-01\n 1128845042    11     11         1 en_NIR_beltel 2019-01-01\n 1128905097    10     10         1 en_NIR_beltel 2019-01-01\n\n\n[1] \"Officer disarmed knifeman in Foyleside Centre court told\"               \n[2] \"Hoaxers are putting lives at risk, warns fire service officer\"          \n[3] \"The volunteers providing a lifeline to elderly Belfast residents\"       \n[4] \"Tributes to Northern Ireland man Christopher Donnelly after death in US\"\n[5] \"Belfast bar to build rooftop terrace in £350k extension\"                \n\n\n\n\n\n4.2.5 Turkey\n\n4.2.5.1 Yeni Sati\n\n\nCorpus consisting of 97638 documents, showing 5 documents:\n\n       Text Types Tokens Sentences        source       date\n 1128735746     4      4         1 tr_TUR_yenisa 2019-01-01\n 1128760707     5      5         1 tr_TUR_yenisa 2019-01-01\n 1128776505     7      7         1 tr_TUR_yenisa 2019-01-01\n 1128776514     7      7         1 tr_TUR_yenisa 2019-01-01\n 1128796514     4      4         1 tr_TUR_yenisa 2019-01-01\n\n\n[1] \"Bingöl'de 4.2 şiddetinde deprem\"                     \n[2] \"Pentagon'da deprem: Görevden alındı\"                 \n[3] \"Cumhurbaşkanı Erdoğan en seçkin dünya lideri seçildi\"\n[4] \"Japonya'da araçlı saldırı: Yayaların arasında daldı\" \n[5] \"Almanya'da Mekke'nin fethi kutlandı\"                 \n\n\n\n\n4.2.5.2 Cumhuryet\n\n\nCorpus consisting of 133713 documents, showing 5 documents:\n\n       Text Types Tokens Sentences        source       date\n 1129020777     7      7         1 tr_TUR_cumhur 2019-01-01\n 1129020771     8      8         1 tr_TUR_cumhur 2019-01-01\n 1129020761     5      5         1 tr_TUR_cumhur 2019-01-01\n 1129000336     6      6         1 tr_TUR_cumhur 2019-01-01\n 1129020744     4      4         1 tr_TUR_cumhur 2019-01-01\n\n\n[1] \"Hakkari-Şırnak kara yolunda çığ düşmesi sonucu kapandı\"\n[2] \"Adana'da 10 araç birbirine girdi: Yaralılar var\"       \n[3] \"CHP binasında  partililerden oturma eylemi\"            \n[4] \"Suriye sınırına askeri sevkiyat devam ediyor\"          \n[5] \"İsveç'te camiye silahlı saldırı\"                       \n\n\n\n\n\n4.2.6 Algeria\n\n4.2.6.1 Al Nahar\n\n\nCorpus consisting of 36341 documents, showing 5 documents:\n\n       Text Types Tokens Sentences        source       date\n 1128917505     4      4         1 ar_DZA_alnaha 2019-01-01\n 1128917491     7      7         1 ar_DZA_alnaha 2019-01-01\n 1128917468     7      7         1 ar_DZA_alnaha 2019-01-01\n 1128917411     5      5         1 ar_DZA_alnaha 2019-01-01\n 1128917432     5      5         1 ar_DZA_alnaha 2019-01-01\n\n\n[1] \"غول يستبعد تأجيل الرئاسيات\"                 \n[2] \"حصيلة الجيش لمختلف العمليات المنفذة في 2018\"\n[3] \"الكاف تُسقط  محرز كأفضل لاعب إفريقي!\"        \n[4] \"صلاح يتفوق على محرز إفريقيا \"               \n[5] \"اتحاد بلعباس في مفترق الطرق \"               \n\n\n\n\n4.2.6.2 El Kahber\n\n\nCorpus consisting of 57230 documents, showing 5 documents:\n\n       Text Types Tokens Sentences        source       date\n 1128760341    10     10         1 ar_DZA_elkahb 2019-01-01\n 1128777970    11     12         2 ar_DZA_elkahb 2019-01-01\n 1128790442     7      7         1 ar_DZA_elkahb 2019-01-01\n 1128804378    11     11         1 ar_DZA_elkahb 2019-01-01\n 1128804373     8      8         1 ar_DZA_elkahb 2019-01-01\n\n\n[1] \"وهران: تأكيد حكم الإعدام لقاتل الطفلة سلسبيل و شريكه\"                 \n[2] \"بونجاح.. الجزائري الوحيد في التشكيلة المثالية للقارة السمراء لـ2018 !\"\n[3] \"إدارة فنربخشة توافق على طلب سليماني !\"                                \n[4] \"وفاة مهندسة في ورشة عدل ببوينان بعد سقوط مواد بناء عليها\"             \n[5] \"إقالة المتحدثة باسم البنتاغون بسبب معاملتها السيئة للموظفين\""
  },
  {
    "objectID": "03-Dictionary.html",
    "href": "03-Dictionary.html",
    "title": "5  Geo-dictionary",
    "section": "",
    "text": "(tbd)"
  },
  {
    "objectID": "04-Tags.html#procedure",
    "href": "04-Tags.html#procedure",
    "title": "6  Geo-tags",
    "section": "6.1 Procedure",
    "text": "6.1 Procedure\n\n6.1.1 Dictionary\nThe dictionary elaborated by automatic procedures has been manually corrected and the new version is upload. As an example, the table below present the labels used for the recognition of the Mediterranean Sea.\n\n\n\n\n\n\nid\nlang\nlabel\ntype\ncode\n\n\n\n\n3211\nQ4918\nar\nالبحر الأبيض المتوسط\nsea\nSE_medit\n\n\n3212\nQ4918\nar\nالبحر المتوسط\nsea\nSE_medit\n\n\n3213\nQ4918\nar\nبحر الروم\nsea\nSE_medit\n\n\n3214\nQ4918\nde\nMittelländisches Meer\nsea\nSE_medit\n\n\n3215\nQ4918\nde\nMittelmeer\nsea\nSE_medit\n\n\n3216\nQ72499\nde\nMittelmeerraum\nsea\nSE_medit\n\n\n3217\nQ72499\nde\nMediterraneum\nsea\nSE_medit\n\n\n3218\nQ4918\nen\nMediterranean\nsea\nSE_medit\n\n\n3219\nQ4918\nen\nMediterranean Sea\nsea\nSE_medit\n\n\n3220\nQ72499\nen\nMediterranean Basin\nsea\nSE_medit\n\n\n3221\nQ72499\nen\nMediterranean region\nsea\nSE_medit\n\n\n3222\nQ4918\nfr\nMéditerranée\nsea\nSE_medit\n\n\n3223\nQ4918\nfr\nMediterranee\nsea\nSE_medit\n\n\n3224\nQ4918\nfr\nmer Méditerranée\nsea\nSE_medit\n\n\n3225\nQ72499\nfr\nbassin méditerranéen\nsea\nSE_medit\n\n\n3226\nQ4918\ntr\nAkdeniz\nsea\nSE_medit\n\n\n3227\nQ72499\ntr\nAkdeniz Havzasi\nsea\nSE_medit\n\n\n\n\n\n\n\n6.1.2 Function\nWe have elaborated a function for the extraction of geographical units based on the dictionary elaborated in previous section (dict) according to the language (lang), the decision to split some tokens (split) to move or not to lower case (tolow) and the possibility to add a list of compounds to be realized (comps) in order to eliminate ambiguities.\nThe code of the function is detailed below :\n\nextract_tags <- function(qd = qd,                      # the corpus of interest\n                         lang = \"fr\",                  # the language to be used\n                         dict = dict,                  # the dictionary of target \n                         code = \"id\" ,                  # variable used for coding\n                         split  = c(\"'\",\"’\",\"-\"),       # split list\n                         tolow = FALSE  ,                # Tokenize text\n                         comps = c(\"Afrique du sud\")  # compounds\n                         )\n{ \n\n\n  \n# Tokenize  \nx<-as.character(qd)\n\n\nif(length(split) > 0) { reg<-paste(split, collapse = '|')\n                       x <- gsub(reg,\" \",x)}  \nif(tolow) { x <- tolower(x)} \ntoks<-tokens(x)\n\n# compounds\nif(length(split) > 0) { reg<-paste(split, collapse = '|')\n                       comps<- gsub(reg,\" \",comps)}  \nif(tolow)       {comps <- tolower(comps)}  \ntoks<-tokens_compound(toks,pattern=phrase(comps))\n\n  \n# Load dictionaries and create compounds\n\n  ## Target dictionary\ndict<-dict[dict$lang==lang & is.na(dict$label)==F,]\ntarget<-dict[ntoken(dict$label)>1,]\nlabels <-dict$label\nif(length(split) > 0) { reg<-paste(split, collapse = '|')\n                       labels<- gsub(reg,\" \",labels)}  \nif(tolow)       {labels <- tolower(labels)}  \ntoks<-tokens_compound(toks,pattern=phrase(labels))\n  \n # create quanteda dictionary\nkeys <-gsub(\" \",\"_\",labels)\nqd_dict<-as.list(keys)\nnames(qd_dict)<-dict[[code]]\nqd_dict<-dictionary(qd_dict,tolower = FALSE)\n\n# Identify geo tags (states or reg or org ...)\ntoks_tags <- tokens_lookup(toks, qd_dict, case_insensitive = F)\ntoks_tags <- lapply(toks_tags, unique)\ntoks_tags<-as.tokens(toks_tags)\nlist_tags<-function(x){res<-paste(x, collapse=' ')}\ndocvars(qd)[[\"tags\"]]<-as.character(lapply(toks_tags,FUN=list_tags))\ndocvars(qd)[[\"nbtags\"]]<-ntoken(toks_tags)\n\n\n\n# Export results\nreturn(qd)\n }\n\n\n\n6.1.3 Tagging\nWe apply the function to the case of Le Figaro. In the case of french language, we provide a list of compounds to be prepared before the application of the dictionary. We also add a supplementary tag that indicates if the news are international. News are considered as international whene at least one world region or foreign state is mentioned. The self reference to the country will not be consiidered as international if they are alone (e.g. a news mentioning only France or Paris in Le Figaro) but will be kept when the nation of the media is combine with another international element (e.g. a news mentioning France in Le Figaro will be kept if it mentions also Europe or Germany )\n\n\n\n\n\n6.1.4 Check\nThen we examine the most frequent tags in international news order to check if results are not too different from expectations :\n\n\n\n\n\nword\nn\n\n\n\n\nST_USA\n2250\n\n\nST_CHN\n1117\n\n\nOR_EU\n1021\n\n\nCO_EUR\n1014\n\n\nST_DEU\n937\n\n\nST_FRA\n936\n\n\nST_ITA\n851\n\n\nST_IRN\n776\n\n\nST_RUS\n729\n\n\nCA_USA\n719"
  },
  {
    "objectID": "04-Tags.html#application",
    "href": "04-Tags.html#application",
    "title": "6  Geo-tags",
    "section": "6.2 Application",
    "text": "6.2 Application\n\n6.2.1 France\n\n6.2.1.1 Le Figaro (FRA)\n\n\n\n\n\n\n\n\nword\nn\n\n\n\n\nST_USA\n2250\n\n\nST_CHN\n1117\n\n\nOR_EU\n1021\n\n\nCO_EUR\n1014\n\n\nST_DEU\n937\n\n\nST_FRA\n936\n\n\nST_ITA\n851\n\n\nST_IRN\n776\n\n\nST_RUS\n729\n\n\nCA_USA\n719\n\n\n\n\n\n\n\n6.2.1.2 Le Monde\n\n\n\n\n\n\n\n\nword\nn\n\n\n\n\nST_USA\n1123\n\n\nST_CHN\n565\n\n\nCO_EUR\n540\n\n\nXX_World\n406\n\n\nOR_EU\n386\n\n\nST_DEU\n384\n\n\nST_DZA\n347\n\n\nST_GBR\n338\n\n\nST_FRA\n315\n\n\nST_ISR\n302\n\n\n\n\n\n\n\n\n6.2.2 Germany\n\n6.2.2.1 FAZ\n\n\n\n\n\n\n\n\nword\nn\n\n\n\n\nOR_EU\n1099\n\n\nXX_America\n877\n\n\nST_CHN\n732\n\n\nCO_EUR\n566\n\n\nST_FRA\n454\n\n\nST_RUS\n384\n\n\nST_ITA\n377\n\n\nST_AFG\n319\n\n\nCA_FRA\n281\n\n\nST_DEU\n270\n\n\n\n\n\n\n\n6.2.2.2 Süddeutsche Zeitung\n\n\n\n\n\n\n\n\nword\nn\n\n\n\n\nST_USA\n864\n\n\nOR_EU\n636\n\n\nST_CHN\n292\n\n\nST_GBR\n278\n\n\nCO_EUR\n257\n\n\nST_AUT\n240\n\n\nST_ITA\n240\n\n\nST_RUS\n212\n\n\nST_FRA\n199\n\n\nST_TUR\n180\n\n\n\n\n\n\n\n\n6.2.3 United Kingdom\n\n6.2.3.1 Guardian\n\n\n\n\n\n\n\n\nword\nn\n\n\n\n\nST_CHN\n1368\n\n\nXX_America\n794\n\n\nST_USA\n746\n\n\nOR_EU\n713\n\n\nST_GBR_ENG\n680\n\n\nST_AUS\n662\n\n\nXX_World\n580\n\n\nST_FRA\n546\n\n\nST_IRN\n539\n\n\nST_IND\n479\n\n\n\n\n\n\n\n6.2.3.2 Daily Telegraph\n\n\n\n\n\n\n\n\nword\nn\n\n\n\n\nST_GBR_ENG\n1120\n\n\nST_CHN\n534\n\n\nOR_EU\n487\n\n\nST_FRA\n375\n\n\nCA_JPN\n358\n\n\nST_ITA\n330\n\n\nXX_World\n287\n\n\nST_IND\n279\n\n\nST_GBR_SCO\n269\n\n\nCO_EUR\n259\n\n\n\n\n\n\n\n\n6.2.4 Ireland & Ulster\n\n6.2.4.1 Belfast Telegraph\nIn the particular case of a media located in Ulster, we decide to filter news speaking only from “Ireland” but to keep news speaking only from UK…\n\n\n\n\n\n\n\n\nword\nn\n\n\n\n\nST_GBR_ENG\n2955\n\n\nST_IRL\n1732\n\n\nST_GBR_SCO\n896\n\n\nST_GBR_WAL\n846\n\n\nCA_GBR\n772\n\n\nOR_EU\n749\n\n\nXX_World\n667\n\n\nST_GBR_NIR\n518\n\n\nCA_IRL\n392\n\n\nST_IND\n387\n\n\n\n\n\n\n\n6.2.4.2 Irish Times\n\n\n\n\n\n\n\n\nword\nn\n\n\n\n\nOR_EU\n1471\n\n\nST_IRL\n1216\n\n\nST_GBR_ENG\n696\n\n\nXX_World\n683\n\n\nST_FRA\n606\n\n\nST_GBR_NIR\n541\n\n\nST_CHN\n525\n\n\nCO_EUR\n462\n\n\nCA_JPN\n424\n\n\nST_GBR\n407\n\n\n\n\n\n\n\n\n6.2.5 Turkey\n\n6.2.5.1 Cumhuryet\n\n\n\n\n\n\n\n\nword\nn\n\n\n\n\nST_USA\n2845\n\n\nST_TUR\n1438\n\n\nST_RUS\n1004\n\n\nCO_EUR\n891\n\n\nST_GBR_ENG\n849\n\n\nST_CHN\n672\n\n\nST_FRA\n562\n\n\nOR_EU\n558\n\n\nST_DEU\n546\n\n\nST_IRN\n532\n\n\n\n\n\n\n\n6.2.5.2 Yeni Safak\n\n\n\n\n\n\n\n\nword\nn\n\n\n\n\nST_USA\n3011\n\n\nST_TUR\n1718\n\n\nST_ISR\n1191\n\n\nST_RUS\n819\n\n\nST_IRN\n790\n\n\nCO_EUR\n743\n\n\nST_CHN\n727\n\n\nST_GBR_ENG\n691\n\n\nST_FRA\n660\n\n\nST_GRC\n654\n\n\n\n\n\n\n\n\n6.2.6 Algeria\n\n6.2.6.1 El Khabar\n\n\n\n\n\n\n\n\nword\nn\n\n\n\n\nST_DZA\n469\n\n\nST_FRA\n462\n\n\nCO_AFR\n286\n\n\nST_TUN\n278\n\n\nCA_TUN\n276\n\n\nST_LBY\n276\n\n\nXX_World\n263\n\n\nST_SAU\n246\n\n\nST_MAR\n231\n\n\nST_EGY\n153\n\n\n\n\n\n\n\n6.2.6.2 Al Nahar (DZA)\n\n\n\n\n\n\n\n\nword\nn\n\n\n\n\nCA_TUN\n353\n\n\nST_TUN\n353\n\n\nST_DZA\n350\n\n\nST_FRA\n324\n\n\nXX_World\n296\n\n\nST_LBY\n279\n\n\nST_MAR\n239\n\n\nCO_AFR\n210\n\n\nST_SAU\n207\n\n\nST_CHN\n159\n\n\n\n\n\n\n\n\n6.2.7 Global corpus"
  },
  {
    "objectID": "05-HyperCubes.html",
    "href": "05-HyperCubes.html",
    "title": "7  HyperCubes",
    "section": "",
    "text": "The aim of this section is to build hypercubes crossing states and regions together or separately and to check their number and share in foreign news."
  },
  {
    "objectID": "05-HyperCubes.html#methods",
    "href": "05-HyperCubes.html#methods",
    "title": "7  HyperCubes",
    "section": "7.1 Methods",
    "text": "7.1 Methods\n\n7.1.1 Separate states and macroregions\nWe proceed firstly to the creation of new columns of geotags where we introduce a distinction between geotags related to states and geotags related to world regions. In the case of states, we merge the geotags obtained by name of the country and the tags obtained by the capital city of the country.\n\nqd<-readRDS(\"quanteda/corpus_worldgeo.RDS\")\n\n\n# take a decision on ambiguous cases ...\nqd$tags<-gsub(\"XX_America\",\"ST_USA\", qd$tags)\nqd$tags<-gsub(\"XX_Congo\",\"ST_COD\",qd$tags)\nqd$tags<-gsub(\"XX_Brussels\",\"OR_EU\",qd$tags)\n\n# Extract regs\nqd$regs<-qd$tags\nqd$regs<-str_replace_all(qd$regs, \"ST_[[:alpha:]_]+\", \"\")\nqd$regs<-str_replace_all(qd$regs, \"CA_[[:alpha:]_]+\", \"\")\nqd$regs<-str_replace_all(qd$regs, \"XX_[[:alpha:]_]+\", \"\")\n\nqd$nbregs<-ntoken(tokens(as.character(qd$regs)))\n\n\n# Extract states\nqd$sta<-qd$tags\nqd$sta<-str_replace_all(qd$sta, \"RE_[[:alpha:]_]+\", \"\")\nqd$sta<-str_replace_all(qd$sta, \"CO_[[:alpha:]_]+\", \"\")\nqd$sta<-str_replace_all(qd$sta, \"OR_[[:alpha:]_]+\", \"\")\nqd$sta<-str_replace_all(qd$sta, \"LA_[[:alpha:]_]+\", \"\")\nqd$sta<-str_replace_all(qd$sta, \"SE_[[:alpha:]_]+\", \"\")\nqd$sta<-str_replace_all(qd$sta, \"CU_[[:alpha:]_]+\", \"\")\nqd$sta<-str_replace_all(qd$sta, \"XX_[[:alpha:]_]+\", \"\")\n\nqd$sta<-str_replace_all(qd$sta, \"ST_\", \"\")\nqd$sta<-str_replace_all(qd$sta, \"CA_\", \"\")\n\n\nqd$nbsta<-ntoken(tokens(as.character(qd$sta)))\nsaveRDS(qd,\"quanteda/corpus_worldgeo_tags.RDS\")\n\nhead(docvars(qd))\nsummary(qd,2)\n\nThe result of the transformation is a table where we can analyze separately the geotags related to states and the geotags related to macroregions :\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsource\ndate\ntags\nnbtags\ninter\nregs\nnbregs\nsta\nnbsta\n\n\n\n\nfr_FRA_figaro\n2019-01-01\n\n0\nFALSE\n\n0\n\n0\n\n\nfr_FRA_figaro\n2019-01-01\nCA_JPN\n1\nTRUE\n\n0\nJPN\n1\n\n\nfr_FRA_figaro\n2019-01-01\nST_THA\n1\nTRUE\n\n0\nTHA\n1\n\n\n\n\n\n\n\n7.1.2 Hypercube function\nThe hypercube fonction produce an agregation of individual news toward a table of count crossing the time period, the media responsible from the news and two spatial dimensions that can be the same dimensions (e.g. state x state or worldregions x worldregions) or two different dimensions (e.g. state x worldregions). The user can choose the level of time agregation (day, week, month, quarter, year), producing a more or less detailed hypercube (with more or less important size)\n\nhypercube <-function(qd = qd,\n                     when = \"date\",\n                     when_cut = \"year\",\n                     who = \"source\",\n                     where1 = \"tags\",\n                     where2 = \"tags\")\n                     \n  {   \n\n# create data.table accroding to parameter chosen\n  don<-docvars(qd)\n\n  df<-data.table(id = docid(qd),\n                 who = don[,who],\n                 when = as.character(cut(don[,when],breaks=when_cut)),\n                 where1 = don[,where1],\n                 where2 = don[,where2])\n\n\n\n# add code _no_ for empty fields\ndf$where1[df$where1==\"\"]<-\"_no_\"\ndf$where2[df$where2==\"\"]<-\"_no_\"\n\n\n# unnest where1\n  df<-unnest_tokens(df,where1,where1,to_lower=F)\n  \n# unnest where2\n  df<-unnest_tokens(df,where2,where2,to_lower=F)  \n  \n# define number of occurence by id\n  nb<-df[,.N,list(id)] %>%  mutate(wgt = 1/N) %>% select(-N)\n  df<-df %>% left_join(nb) \n  \n  rm(nb)\n \n# Aggregate\n  hc<- df[,.( tags = .N, news=sum(wgt)) ,.(who, when,where1,where2)]\n  \n# Convert date to time\n  hc$when<-as.Date(hc$when)\n  \n# return hypercube\n  return(hc)\n\n}\n\n\n\n7.1.3 Geotags x Geotags\nWe can fistly cross the geotags without any modifications in order to keep the maximum of information :\n\n#qd<-readRDS(\"quanteda/corpus_worldgeo.RDS\")\n# Create Global hypercube\nhc_geo <- hypercube(qd = qd,\n                     when = \"date\",\n                     when_cut = \"day\",\n                     who = \"source\",\n                     where1 = \"tags\",\n                     where2 = \"tags\")\n\nsaveRDS(hc_geo,\"hypercube/hc_geo_geo_day.RDS\")\n\nWe obtain an hypercube where it is for example possible to identify title of news crossing “Moscow” (CA_RUS) and “European Union” (OR_UE). In this case we can still distinguish the cases where Russia is identified by the name of the capital (Moscow) or the name of the country (Russia). This distinction can be very useful when the capital of a state is also the capital of a macroregion. For example, the case of “Bruxelles” is a good example where the word can be interpreted as the capital city of Belgium (CA_BEL) or a metaphoric way to name European Union (OR_EU).\n\n\n             who       when where1 where2 tags      news\n1: fr_FRA_figaro 2019-01-21 CA_RUS  OR_EU    1 0.2500000\n2: fr_FRA_figaro 2019-04-25 CA_RUS  OR_EU    1 0.1111111\n3: fr_FRA_figaro 2019-06-20 CA_RUS  OR_EU    1 0.2500000\n4: fr_FRA_figaro 2020-07-02 CA_RUS  OR_EU    1 0.1111111\n5: fr_FRA_figaro 2020-08-28 CA_RUS  OR_EU    1 0.1111111\n6: fr_FRA_figaro 2020-09-04 CA_RUS  OR_EU    1 0.2500000\n\n\n\n\n7.1.4 State x State\nIn this second table we do not consider the macroregion but we just analyze the associations of statesn without any distinction between the case where the state is identified by the name of the city or the name of the country\n\n# Create State hypercube\nhc_sta <- hypercube(qd = qd,\n                     when = \"date\",\n                     when_cut = \"day\",\n                     who = \"source\",\n                     where1 = \"sta\",\n                     where2 = \"sta\")\n\nsaveRDS(hc_sta,\"hypercube/hc_sta_sta_day.RDS\")\n\nWe obtain an hypercube where it is possible to identify precisely the number of time where Russia (CA_RUS or ST_RUS) has been associated to Ukraine (CA_UKR or ST_UKR) in the same title of news. This hypercube will be very usefull if we want to examine the network of association between countries and build a model of dominant flows, backbones, Louvain communities, etc… The simplification of the code to ISO3 make also possible to produce easily maps of the country the most mentionned.\n\n\n             who       when where1 where2 tags      news\n1: fr_FRA_figaro 2019-01-31    RUS    UKR    1 0.2500000\n2: fr_FRA_figaro 2019-03-28    RUS    UKR    1 0.2500000\n3: fr_FRA_figaro 2019-04-22    RUS    UKR    1 0.2500000\n4: fr_FRA_figaro 2019-04-25    RUS    UKR    2 0.5000000\n5: fr_FRA_figaro 2019-05-20    RUS    UKR    1 0.2500000\n6: fr_FRA_figaro 2019-06-04    RUS    UKR    2 0.2222222\n\n\n\n\n7.1.5 Worldregion x Worldegion\nWe follow here exactly the same procedure but using only worldregions and excluding states.\n\n# Create Regional hypercube\nhc_reg <- hypercube(qd = qd,\n                     when = \"date\",\n                     when_cut = \"day\",\n                     who = \"source\",\n                     where1 = \"regs\",\n                     where2 = \"regs\")\n\nsaveRDS(hc_reg,\"hypercube/hc_reg_reg_day.RDS\")\n\nWe obtain an hypercube where it is possible to identify precisely the number of time where “NATO” (OR_NATO) has been associated to “Europe” (CO_EUR) in the same title of news. We can therefore analyze cases of preferential linkage between macroregions. And we could for example answer to the question : is NATO more frequently associated to Europe (continent) or European Union (organization) ?\n\n\n             who       when  where1 where2 tags      news\n1: fr_FRA_figaro 2019-07-05 OR_NATO CO_EUR    1 0.2500000\n2: fr_FRA_figaro 2020-11-02 OR_NATO CO_EUR    1 0.1111111\n3: fr_FRA_figaro 2020-12-09 OR_NATO CO_EUR    1 0.2500000\n4: fr_FRA_figaro 2021-06-23 OR_NATO CO_EUR    1 0.2500000\n5: fr_FRA_lmonde 2021-09-13 OR_NATO CO_EUR    1 0.2500000\n6: de_DEU_suddeu 2019-02-12 OR_NATO CO_EUR    1 0.2500000\n\n\n\n\n7.1.6 Worlregion x States\nThis final case where we combine states on the one hand and organizations on the other hand is particularly interesting if our target is to discover process than can contribut to the construction of mental maps and representations. They are indeed many reasons that can produce the association between a state and a world region in the title of a news. But the repetition of the same associations produce a structural pattern that can shape to some extent the imagination.\n\n# Create State x Reg hypercube\nhc_sta_reg <- hypercube(qd = qd,\n                     when = \"date\",\n                     when_cut = \"day\",\n                     who = \"source\",\n                     where1 = \"sta\",\n                     where2 = \"regs\")\n\nsaveRDS(hc_sta_reg,\"hypercube/hc_sta_reg_day.RDS\")\n\nWith this type of hypercube, we can for example examine how many time, when and by whom, the titles of news has associated Turkey (TUR) identified by its name (ST_TUR) or its capital Ankara (CA_TUR) with European Union (OR_EU) or Europe (CO_EUR) and what is the most frequent pattern.\n\n\n             who       when where1 where2 tags news\n1: fr_FRA_figaro 2019-06-18    TUR  OR_EU    1  0.5\n2: fr_FRA_figaro 2019-07-16    TUR  OR_EU    2  1.5\n3: fr_FRA_figaro 2019-10-07    TUR  OR_EU    1  0.5\n4: fr_FRA_figaro 2019-10-19    TUR  OR_EU    1  0.5\n5: fr_FRA_figaro 2020-01-19    TUR  OR_EU    1  0.5\n6: fr_FRA_figaro 2020-02-28    TUR  OR_EU    1  1.0"
  },
  {
    "objectID": "05-HyperCubes.html#agregation",
    "href": "05-HyperCubes.html#agregation",
    "title": "7  HyperCubes",
    "section": "7.2 Agregation",
    "text": "7.2 Agregation\nThe hypercubes are objects of relatively small size as compared to quanteda object because the text of news has been removed and we keep only the count of news. Hypercubes are very efficient for the production of simple table or cross tables. Here we use the package data.tablewhich is very fast and efficient for large data sets. But it is generally sufficient to use the tools of the package tidyverse and in particular dplyrto obtain the same results.\n\n7.2.1 International news\nHow many news can be considered as international ? We use here the presence of either a country or a macroregion in the title as criterium of identification of what is “international” and what is not. This proxy is certainly not perfect (especially considering the fact that for the moment we do not take into account the fact that the country mentionned can be the state where the media is located) but it is sufficient to get a raw approximation.\n\n\n\nShare of international news\n\n\nMedia\nTotal\nFrequence\nPourcentage\n\n\n\n\nar_DZA_alnaha\n35152\n6525\n18.56\n\n\nar_DZA_elkahb\n56836\n7936\n13.96\n\n\nde_DEU_frankf\n88071\n13810\n15.68\n\n\nde_DEU_suddeu\n35397\n7242\n20.46\n\n\nen_GBR_guardi\n77046\n18808\n24.41\n\n\nen_GBR_telegr\n37904\n8915\n23.52\n\n\nen_IRL_irtime\n106753\n20991\n19.66\n\n\nen_NIR_beltel\n99060\n19473\n19.66\n\n\nfr_FRA_figaro\n128289\n37300\n29.07\n\n\nfr_FRA_lmonde\n49555\n16116\n32.52\n\n\ntr_TUR_cumhur\n131449\n20569\n15.65\n\n\ntr_TUR_yenisa\n96171\n22532\n23.43\n\n\nTotal\n941683\n200217\n21.26\n\n\n\n\n\n\nComment : We have found 200217 international news on the total of 941683 titles of news present in the corpus. The proportion is therefore equal to 21.2 % but with important variations between the newspapers, from 14 to 32%.\n\n\n\n7.2.2 Macroregional news\nA news will be defined as macroregional if we can find at less a name of macroregion (continent, organization, ocean) in the title.\n\n\n\nShare of news mentionning a macroregion\n\n\nMedia\nTotal\nFrequence\nPourcentage\n\n\n\n\nar_DZA_alnaha\n34191\n613\n1.79\n\n\nar_DZA_elkahb\n55963\n610\n1.09\n\n\nde_DEU_frankf\n86884\n2345\n2.70\n\n\nde_DEU_suddeu\n34877\n1277\n3.66\n\n\nen_GBR_guardi\n74783\n2170\n2.90\n\n\nen_GBR_telegr\n36591\n1154\n3.15\n\n\nen_IRL_irtime\n104330\n2533\n2.43\n\n\nen_NIR_beltel\n96395\n1385\n1.44\n\n\nfr_FRA_figaro\n123951\n4281\n3.45\n\n\nfr_FRA_lmonde\n47820\n2070\n4.33\n\n\ntr_TUR_cumhur\n128664\n2926\n2.27\n\n\ntr_TUR_yenisa\n92566\n3057\n3.30\n\n\nTotal\n917015\n24421\n2.66\n\n\n\n\n\n\nComment : We have found 24421 macroregional news on the total of 941683 titles of news present in the corpus. The proportion is therefore equal to 2.7 % but with important variations between the newspapers, from 1.1 to 4.4%.\n\n\n\n7.2.3 State news\nWe will define a state news as a news where at less one name of country or capital of country is present in the title. For the moment we do not control the fact that the country mentioned is the country where the media is located or not.\n\n\n\nShare of news mentioning a state\n\n\nMedia\nTotal\nFrequence\nPourcentage\n\n\n\n\nar_DZA_alnaha\n35141\n4106\n11.68\n\n\nar_DZA_elkahb\n56824\n4418\n7.77\n\n\nde_DEU_frankf\n87995\n10091\n11.47\n\n\nde_DEU_suddeu\n35332\n5501\n15.57\n\n\nen_GBR_guardi\n76998\n16261\n21.12\n\n\nen_GBR_telegr\n37871\n6816\n18.00\n\n\nen_IRL_irtime\n106697\n10520\n9.86\n\n\nen_NIR_beltel\n99036\n18038\n18.21\n\n\nfr_FRA_figaro\n128159\n27332\n21.33\n\n\nfr_FRA_lmonde\n49484\n11368\n22.97\n\n\ntr_TUR_cumhur\n131396\n14135\n10.76\n\n\ntr_TUR_yenisa\n96100\n15968\n16.62\n\n\nTotal\n941033\n144553\n15.36\n\n\n\n\n\n\nComment : We have found 1424553 state news on the total of 941683 titles of news present in the corpus. The proportion is therefore equal to 15 % but with important variations between the newspapers, from 7.8 to 22.3%.\n\n\n\n7.2.4 State & macroregional news\n\n\n\nShare of news mentioning a macroregion and a state\n\n\nMedia\nTotal\nFrequence\nPourcentage\n\n\n\n\nar_DZA_alnaha\n34180\n140\n0.41\n\n\nar_DZA_elkahb\n55951\n140\n0.25\n\n\nde_DEU_frankf\n86808\n597\n0.69\n\n\nde_DEU_suddeu\n34812\n374\n1.07\n\n\nen_GBR_guardi\n74735\n621\n0.83\n\n\nen_GBR_telegr\n36558\n336\n0.92\n\n\nen_IRL_irtime\n104274\n661\n0.63\n\n\nen_NIR_beltel\n96371\n341\n0.35\n\n\nfr_FRA_figaro\n123821\n1623\n1.31\n\n\nfr_FRA_lmonde\n47749\n687\n1.44\n\n\ntr_TUR_cumhur\n128611\n905\n0.70\n\n\ntr_TUR_yenisa\n92495\n1095\n1.18\n\n\nTotal\n916365\n7520\n0.82\n\n\n\n\n\n\nComment : We have found only 7520 news that fulfill both conditions of mentioning a state and a macroregion. The proportion is therefore equal to 0.82 % but with important variations between the newspapers, from 0.25 to 1.18%."
  },
  {
    "objectID": "06-Macroregions.html#data",
    "href": "06-Macroregions.html#data",
    "title": "8  MacroRegions",
    "section": "8.1 Data",
    "text": "8.1 Data\nWe laod an hypercube where the text of news has been removed and where we keep only the number of tags or proportion of news speaking from one or several regions (where1, where2), by media (who) and by time period (when)"
  },
  {
    "objectID": "06-Macroregions.html#top-50-regions-in-full-corpus",
    "href": "06-Macroregions.html#top-50-regions-in-full-corpus",
    "title": "8  MacroRegions",
    "section": "8.2 Top 50 regions in full corpus",
    "text": "8.2 Top 50 regions in full corpus\n\n8.2.1 Unweighted\nWe can propose firstly a table of top entities in the whole corpus of newspapers with index 100 for the first entity.\n\n\n\n\n\n\ncode\ntype\nlabel\nnb\nindex\n\n\n\n\n1\nOR_EU\norg\nEuropean Union\n7656\n100.00\n\n\n2\nCO_EUR\ncont\nEurope\n4763\n62.21\n\n\n3\nOR_UN\norg\nUnited Nations\n2209\n28.86\n\n\n4\nCO_AFR\ncont\nAfrica\n1309\n17.10\n\n\n5\nSE_medit\nsea\nMediterranean Sea\n871\n11.38\n\n\n6\nOR_NATO\norg\nNATO\n748\n9.77\n\n\n7\nCO_ASI_minor\ncont\nAsia Minor\n437\n5.70\n\n\n8\nSE_black\nsea\nBlack Sea\n365\n4.77\n\n\n9\nLA_east_middle\nland\nMiddle East\n330\n4.31\n\n\n10\nCO_ASI\ncont\nAsia\n324\n4.23\n\n\n11\nOR_Eurovision\norg\nEurovision\n208\n2.72\n\n\n12\nSE_arcti\nsea\nArctic\n186\n2.44\n\n\n13\nLA_sahel\nland\nSahel\n184\n2.41\n\n\n14\nLA_alpen\nland\nAlps\n175\n2.29\n\n\n15\nCO_AMR_latin\ncont\nLatin America\n142\n1.85\n\n\n16\nLA_amazon\nland\nAmazonia\n130\n1.70\n\n\n17\nCO_ANT\ncont\nAntarctica\n111\n1.45\n\n\n18\nOR_CoEur\norg\nCouncil of Europe\n87\n1.14\n\n\n19\nSE_carai\nsea\nCaribbean\n80\n1.05\n\n\n20\nLA_east_near\nland\nNear East\n76\n0.99\n\n\n21\nCO_AMR_south\ncont\nSouth America\n73\n0.96\n\n\n22\nCU_arab\ncult\nArab World\n68\n0.89\n\n\n23\nCO_ERA\ncont\nEurasia\n67\n0.88\n\n\n24\nLA_sahara\nland\nSahara\n64\n0.84\n\n\n25\nCU_Occident\ncult\nWestern world\n62\n0.82\n\n\n26\nCO_AMR_centr\ncont\nCentral America\n51\n0.67\n\n\n27\nOR_Merco\norg\nMercosur\n51\n0.67\n\n\n28\nLA_balka\nland\nBalkans\n49\n0.64\n\n\n29\nCO_AFR_west\ncont\nWest Africa\n48\n0.62\n\n\n30\nLA_himal\nland\nHimalayas\n40\n0.53\n\n\n31\nOR_ArLig\norg\nArab League\n40\n0.52\n\n\n32\nOR_comwl\norg\nCommonwealth of Nations\n38\n0.50\n\n\n33\nOR_Schengen\norg\nSchengen Area\n38\n0.50\n\n\n34\nSE_antil\nsea\nAntilles\n36\n0.47\n\n\n35\nSE_polyn\nsea\nPolynesia\n36\n0.46\n\n\n36\nLA_maghr\nland\nMashriq\n35\n0.46\n\n\n37\nCO_ASI_south_east\ncont\nSoutheast Asia\n34\n0.44\n\n\n38\nLA_cauca\nland\nCaucasus\n34\n0.44\n\n\n39\nCO_AMR_north\ncont\nNorth America\n33\n0.43\n\n\n40\nCO_AMR_north\ncont\nNorthern America\n33\n0.43\n\n\n41\nSE_china\nsea\nChina Sea\n33\n0.43\n\n\n42\nSE_persi\nsea\nPersian Gulf\n32\n0.41\n\n\n43\nOR_AfrUn\norg\nAfrican Union\n29\n0.38\n\n\n44\nCU_Orient\ncult\nOrient\n29\n0.38\n\n\n45\nCO_AMR\ncont\nAmericas\n28\n0.37\n\n\n46\nCO_EUR_east\ncont\nEast-Central Europe\n24\n0.32\n\n\n47\nSE_india\nsea\nIndian Ocean\n22\n0.29\n\n\n48\nCO_ASI_pacif\ncont\nAsia-Pacific\n22\n0.28\n\n\n49\nCO_AFR_east\ncont\nEast Africa\n20\n0.25\n\n\n50\nCO_AFR_ssahr\ncont\nSub-Saharan Africa\n19\n0.25\n\n\n\n\n\n\n\n8.2.2 Weighted\n\n\n\n\n\n\ncode\ntype\nlabel\nnb\nindex\n\n\n\n\n1\nOR_EU\norg\nEuropean Union\n7566\n100.00\n\n\n2\nCO_EUR\ncont\nEurope\n4570\n60.41\n\n\n3\nCO_AFR\ncont\nAfrica\n2370\n31.32\n\n\n4\nOR_UN\norg\nUnited Nations\n2032\n26.86\n\n\n5\nSE_medit\nsea\nMediterranean Sea\n707\n9.35\n\n\n6\nOR_NATO\norg\nNATO\n619\n8.18\n\n\n7\nCO_ASI\ncont\nAsia\n379\n5.00\n\n\n8\nLA_east_middle\nland\nMiddle East\n378\n4.99\n\n\n9\nCO_ASI_minor\ncont\nAsia Minor\n309\n4.08\n\n\n10\nSE_black\nsea\nBlack Sea\n259\n3.43\n\n\n11\nOR_Eurovision\norg\nEurovision\n221\n2.92\n\n\n12\nLA_sahel\nland\nSahel\n218\n2.88\n\n\n13\nSE_arcti\nsea\nArctic\n180\n2.38\n\n\n14\nCU_arab\ncult\nArab World\n158\n2.09\n\n\n15\nLA_alpen\nland\nAlps\n141\n1.87\n\n\n16\nCO_AMR_latin\ncont\nLatin America\n131\n1.73\n\n\n17\nLA_amazon\nland\nAmazonia\n102\n1.34\n\n\n18\nCO_ANT\ncont\nAntarctica\n98\n1.30\n\n\n19\nCO_AMR_south\ncont\nSouth America\n87\n1.15\n\n\n20\nSE_carai\nsea\nCaribbean\n85\n1.13\n\n\n21\nCU_Occident\ncult\nWestern world\n84\n1.11\n\n\n22\nOR_ArLig\norg\nArab League\n75\n1.00\n\n\n23\nOR_CoEur\norg\nCouncil of Europe\n63\n0.83\n\n\n24\nLA_maghr\nland\nMashriq\n63\n0.83\n\n\n25\nLA_east_near\nland\nNear East\n61\n0.81\n\n\n26\nOR_Schengen\norg\nSchengen Area\n54\n0.71\n\n\n27\nOR_comwl\norg\nCommonwealth of Nations\n54\n0.71\n\n\n28\nCO_AFR_west\ncont\nWest Africa\n53\n0.70\n\n\n29\nCO_ERA\ncont\nEurasia\n47\n0.62\n\n\n30\nLA_sahara\nland\nSahara\n47\n0.62\n\n\n31\nCO_AMR_centr\ncont\nCentral America\n45\n0.60\n\n\n32\nLA_balka\nland\nBalkans\n43\n0.57\n\n\n33\nOR_Merco\norg\nMercosur\n39\n0.52\n\n\n34\nLA_himal\nland\nHimalayas\n35\n0.46\n\n\n35\nSE_china\nsea\nChina Sea\n33\n0.43\n\n\n36\nCO_ASI_south_east\ncont\nSoutheast Asia\n33\n0.43\n\n\n37\nSE_persi\nsea\nPersian Gulf\n30\n0.39\n\n\n38\nCO_AMR\ncont\nAmericas\n29\n0.39\n\n\n39\nCO_AMR_north\ncont\nNorth America\n29\n0.38\n\n\n40\nCO_AMR_north\ncont\nNorthern America\n29\n0.38\n\n\n41\nOR_AfrUn\norg\nAfrican Union\n27\n0.36\n\n\n42\nLA_cauca\nland\nCaucasus\n24\n0.31\n\n\n43\nSE_india\nsea\nIndian Ocean\n22\n0.29\n\n\n44\nSE_antil\nsea\nAntilles\n21\n0.28\n\n\n45\nCO_EUR_east\ncont\nEast-Central Europe\n21\n0.28\n\n\n46\nSE_polyn\nsea\nPolynesia\n19\n0.26\n\n\n47\nCU_Orient\ncult\nOrient\n18\n0.24\n\n\n48\nCO_AFR_east\ncont\nEast Africa\n18\n0.24\n\n\n49\nSE_atlan\nsea\nAtlantic Ocean\n17\n0.23\n\n\n50\nCO_ASI_pacif\ncont\nAsia-Pacific\n17\n0.22"
  },
  {
    "objectID": "06-Macroregions.html#top-10-regions-by-media",
    "href": "06-Macroregions.html#top-10-regions-by-media",
    "title": "8  MacroRegions",
    "section": "8.3 Top 10 regions by media",
    "text": "8.3 Top 10 regions by media\n\n8.3.1 German newspapers - Top 10 regions\n\n\n\n\n\nRank\nFrankf. Allg. Zeit.\nindex\nSüdeutsche Zeit.\nindex\n\n\n\n\n1\nEuropean Union\n100.0\nEuropean Union\n100.0\n\n\n2\nEurope\n47.3\nEurope\n36.9\n\n\n3\nNATO\n10.3\nUnited Nations\n8.8\n\n\n4\nUnited Nations\n9.7\nMiddle East\n7.9\n\n\n5\nAfrica\n6.6\nNATO\n6.7\n\n\n6\nMediterranean Sea\n3.9\nAfrica\n6.1\n\n\n7\nAsia\n3.1\nMediterranean Sea\n5.0\n\n\n8\nMiddle East\n3.0\nAlps\n2.8\n\n\n9\nAlps\n2.5\nEurovision\n2.2\n\n\n10\nArctic\n1.5\nAsia\n1.6\n\n\n\n\n\n\n\n8.3.2 French newspapers - Top 10 regions\n\n\n\n\n\nRank\nLe Figaro\nindex\nLe Monde\nindex\n\n\n\n\n1\nEuropean Union\n100.0\nEurope\n100.0\n\n\n2\nEurope\n78.0\nEuropean Union\n90.9\n\n\n3\nUnited Nations\n54.4\nAfrica\n41.7\n\n\n4\nMediterranean Sea\n10.9\nUnited Nations\n36.8\n\n\n5\nAfrica\n9.3\nSahel\n13.0\n\n\n6\nAmazonia\n7.6\nMediterranean Sea\n11.1\n\n\n7\nNATO\n7.4\nNear East\n6.2\n\n\n8\nSahel\n6.4\nAmazonia\n6.2\n\n\n9\nAlps\n6.0\nNATO\n6.2\n\n\n10\nMiddle East\n4.2\nAlps\n6.1\n\n\n\n\n\n\n\n8.3.3 UK newspapers - Top 10 regions\n\n\n\n\n\nRank\nThe Guardian\nindex\nThe Daily Telegraph\nindex\n\n\n\n\n1\nEuropean Union\n100.0\nEuropean Union\n100.0\n\n\n2\nUnited Nations\n55.6\nEurope\n41.2\n\n\n3\nEurope\n54.7\nUnited Nations\n14.1\n\n\n4\nAfrica\n14.3\nAfrica\n12.5\n\n\n5\nArctic\n9.8\nAsia\n4.4\n\n\n6\nMiddle East\n9.6\nEurovision\n3.9\n\n\n7\nNATO\n6.6\nWestern world\n3.7\n\n\n8\nLatin America\n4.5\nMiddle East\n2.5\n\n\n9\nAsia\n4.4\nArctic\n2.1\n\n\n10\nAntarctica\n3.8\nCaribbean\n1.9\n\n\n\n\n\n\n\n8.3.4 Irish newspapers - Top 10 regions\n\n\n\n\n\nRank\nIrish Times\nindex\nBelfast Telegraph\nindex\n\n\n\n\n1\nEuropean Union\n100.0\nEuropean Union\n100.0\n\n\n2\nEurope\n27.4\nEurope\n21.2\n\n\n3\nUnited Nations\n11.1\nUnited Nations\n9.5\n\n\n4\nEurovision\n2.9\nEurovision\n5.7\n\n\n5\nAfrica\n2.5\nAfrica\n3.2\n\n\n6\nNATO\n2.1\nArctic\n2.8\n\n\n7\nAsia\n2.0\nCommonwealth of Nations\n2.6\n\n\n8\nMiddle East\n1.8\nAsia\n2.2\n\n\n9\nMediterranean Sea\n1.4\nMiddle East\n2.1\n\n\n10\nWestern world\n1.0\nNATO\n1.8\n\n\n\n\n\n\n\n8.3.5 Turkish newspapers - Top 10 regions\n\n\n\n\n\nRank\nCumhurryet\nindex\nYeni Savak\nindex\n\n\n\n\n1\nEurope\n100.0\nEurope\n100.0\n\n\n2\nEuropean Union\n67.9\nEuropean Union\n83.9\n\n\n3\nAsia Minor\n38.6\nMediterranean Sea\n51.5\n\n\n4\nMediterranean Sea\n32.7\nUnited Nations\n47.8\n\n\n5\nNATO\n24.5\nBlack Sea\n34.0\n\n\n6\nUnited Nations\n24.1\nNATO\n33.4\n\n\n7\nBlack Sea\n18.7\nAsia Minor\n26.1\n\n\n8\nAfrica\n11.2\nAfrica\n19.3\n\n\n9\nAsia\n5.7\nAsia\n6.1\n\n\n10\nEurasia\n4.7\nEurasia\n5.5\n\n\n\n\n\n\n\n8.3.6 Algerian newspapers\n\n\n\n\n\nRank\nAl Nahar\nindex\nEl Khabar\nindex\n\n\n\n\n1\nAfrica\n100.0\nAfrica\n100.0\n\n\n2\nEurope\n61.1\nEurope\n33.4\n\n\n3\nEuropean Union\n24.4\nUnited Nations\n21.6\n\n\n4\nUnited Nations\n23.9\nEuropean Union\n13.1\n\n\n5\nSahel\n10.1\nArab World\n8.5\n\n\n6\nAsia\n9.5\nMediterranean Sea\n6.6\n\n\n7\nArab World\n9.0\nAsia\n5.9\n\n\n8\nMiddle East\n6.5\nMiddle East\n4.1\n\n\n9\nArab League\n6.0\nMashriq\n3.3\n\n\n10\nMediterranean Sea\n4.5\nSchengen Area\n3.3"
  },
  {
    "objectID": "06-Macroregions.html#synthesis-by-correspondance-analysis-and-hierarchical-clustering",
    "href": "06-Macroregions.html#synthesis-by-correspondance-analysis-and-hierarchical-clustering",
    "title": "8  MacroRegions",
    "section": "8.4 Synthesis by correspondance analysis and Hierarchical Clustering",
    "text": "8.4 Synthesis by correspondance analysis and Hierarchical Clustering\nThe synthesis is realized with regions\n\n8.4.1 Factor 1-2\n\n\n\n\n\n\n\n\n8.4.2 Factors 3-4\n\n\n\n\n\n\n\n\n8.4.3 Cluster analysis (world regions)\n\n\n\n\n\n\n\n8.4.4 Cluster analysis (medias)"
  },
  {
    "objectID": "06-Macroregions.html#synthesis-by-chi-square-heatmap",
    "href": "06-Macroregions.html#synthesis-by-chi-square-heatmap",
    "title": "8  MacroRegions",
    "section": "8.5 Synthesis by chi-square & heatmap",
    "text": "8.5 Synthesis by chi-square & heatmap\nAn alternative approach based on the computation of chi-square and the classification of residuals (censoredd between -3 and +3)"
  },
  {
    "objectID": "07-Agenda.html",
    "href": "07-Agenda.html",
    "title": "9  Agenda",
    "section": "",
    "text": "In this section we try to define an alternative measure of salience of a geographical entity (region or state) base on the duration of presence in the agenda rather than on the total number of news. As we are speaking from daily newspapers, we will try to estimate the number of days where an entity is present over a time period."
  },
  {
    "objectID": "07-Agenda.html#data",
    "href": "07-Agenda.html#data",
    "title": "9  Agenda",
    "section": "9.1 Data",
    "text": "9.1 Data\nWe load an hypercube of news related to two newspaper (Le Figaro and Le Monde) characterized by an important an regular flow of news with an important proportion of international news. We consider two time periods of one year, 2019 and 2020.\n\n\n\n\n9.1.1 Boolean table\nWe create for each type of geographical entities a boolean matrix crossing the existence or non existence of a newsby date\n\n# Le Figaro\ntab1<-hc_figaro[,.(n=min(1,.N)),.(where1,when)] %>% dcast(formula = when~where1,fill = 0) \ntab2<-hc_figaro[,.(n=min(1,.N)),.(where2,when)] %>% dcast(formula = when~where2,fill = 0) \ntab_figaro<-cbind(tab1,tab2)\n\nkable(tab_figaro[1:10,c(\"when\",\"FRA\",\"GBR\",\"RUS\",\"USA\",\"CHN\",\"OR_EU\",\"CO_EUR\")], \n      caption = \"Extract from boolean matrix of Le Figaro\")\n\n\nExtract from boolean matrix of Le Figaro\n\n\nwhen\nFRA\nGBR\nRUS\nUSA\nCHN\nOR_EU\nCO_EUR\n\n\n\n\n2019-01-01\n1\n0\n0\n0\n0\n0\n0\n\n\n2019-01-02\n1\n0\n1\n1\n1\n0\n1\n\n\n2019-01-03\n1\n1\n1\n1\n1\n1\n0\n\n\n2019-01-04\n1\n1\n1\n1\n1\n0\n1\n\n\n2019-01-05\n1\n0\n0\n0\n0\n0\n0\n\n\n2019-01-06\n1\n0\n0\n1\n0\n0\n0\n\n\n2019-01-07\n1\n0\n0\n1\n1\n1\n1\n\n\n2019-01-08\n1\n1\n0\n1\n1\n1\n0\n\n\n2019-01-09\n1\n1\n1\n1\n0\n1\n0\n\n\n2019-01-10\n1\n0\n0\n0\n1\n1\n1\n\n\n\n\n# Le Monde\ntab1<-hc_lmonde[,.(n=min(1,.N)),.(where1,when)] %>% dcast(formula = when~where1,fill = 0) \ntab2<-hc_lmonde[,.(n=min(1,.N)),.(where2,when)] %>% dcast(formula = when~where2,fill = 0) \ntab_lmonde<-cbind(tab1,tab2)\n\nkable(tab_lmonde[1:10,c(\"when\",\"FRA\",\"GBR\",\"RUS\",\"USA\",\"CHN\",\"OR_EU\",\"CO_EUR\")], \n      caption = \"Extract from boolean matrix of Le Monde\")\n\n\nExtract from boolean matrix of Le Monde\n\n\nwhen\nFRA\nGBR\nRUS\nUSA\nCHN\nOR_EU\nCO_EUR\n\n\n\n\n2019-01-01\n0\n0\n1\n0\n0\n0\n0\n\n\n2019-01-02\n0\n1\n0\n1\n1\n0\n0\n\n\n2019-01-03\n1\n0\n0\n1\n0\n0\n0\n\n\n2019-01-04\n1\n0\n0\n1\n0\n0\n0\n\n\n2019-01-05\n1\n0\n0\n0\n0\n0\n0\n\n\n2019-01-06\n1\n0\n0\n0\n0\n0\n0\n\n\n2019-01-07\n1\n0\n0\n0\n0\n0\n0\n\n\n2019-01-08\n1\n0\n0\n0\n1\n0\n0\n\n\n2019-01-09\n1\n1\n0\n1\n0\n0\n0\n\n\n2019-01-10\n1\n0\n1\n1\n0\n0\n1\n\n\n\n\n\n\n\n9.1.2 Visualization\nAn interesting solution for the visualization of such boolean data is the use of X-ray diagrams used in textual analysis for the visualization of wrods distribution in a text."
  },
  {
    "objectID": "07-Agenda.html#models",
    "href": "07-Agenda.html#models",
    "title": "9  Agenda",
    "section": "9.2 Models",
    "text": "9.2 Models\nDifferent options of modelling are available for the evaluation of the cross-effects of media (m) and time period (t) on the probability to find a given number of news speaking from a geographical entity (s). We can separate initialy two family of models :\n\nPoisson models family will evaluate the number of news from media m at time t speaking from spatial object s (Nmts) as a function of the total number of news produced during the same period by the same media (Nmt) and parameters to be estimated concerning peaks of interest during certain periods of time (k1..kt) and specific focus of some medias on the spatial object (w1..wm).\nLogit models family will use a boolean approach and try to evaluate what is the probabilty to have at least one news about the spatial unit during a period of time which could typically a day as we are examining daily newspapers. This second family of models fit better in our opinion to the problem of measure of the agendas.\n\nNot necessary to add that both models can finally be combine in hybrid models like the zero-inflated Poisson model which will be analyzed in final part of the discussion.\n\n9.2.1 Preparation of data"
  },
  {
    "objectID": "08-Network-Analysis.html",
    "href": "08-Network-Analysis.html",
    "title": "10  Network analysis",
    "section": "",
    "text": "library(quanteda, quiet=T)\n#library(readr)\nlibrary(knitr)\n#library(ggplot2)\nlibrary(data.table)\n#library(lubridate, quiet=T)\n#library(tidytext, quiet=T)\n#library(stringr)\n#library(visNetwork, quietly = T)\nlibrary(dplyr)\nlibrary(reshape2)\nlibrary(igraph)\nlibrary(pheatmap)\n\n\n\n# function\nhc_filter <- function(don = hc,\n                      who = \"who\",\n                      when = \"when\",\n                      where1 = \"where1\",\n                      where2 = \"where2\",\n                      wgt = \"tags\",\n                      self = FALSE,\n                      when_start = NA,\n                      when_end = NA,\n                      who_exc = NA,\n                      who_inc = NA,\n                      where1_exc = NA,\n                      where1_inc = NA,\n                      where2_exc = NA,\n                      where2_inc = NA)\n\n{                          \n  \n  df<-data.table(who = don[[who]],\n                 when = don[[when]],\n                 where1 = don[[where1]],\n                 where2 = don[[where2]],\n                 wgt = don[[wgt]])\n  \n  \n  # Select time period\n  if (is.na(when_start[1])==FALSE) { \n    df <- df[when >= as.Date(when_start), ]}\n  if (is.na(when_end[1])==FALSE) { \n    df <- df[when <= as.Date(when_end), ]}\n  # Select who\n  if (is.na(who_exc[1])==FALSE) { \n    df <- df[!(who %in% who_exc), ]}\n  if (is.na(who_inc[1])==FALSE) { \n    df <- df[(who %in% who_inc), ]}\n  # Select where1\n  if (is.na(where1_exc[1])==FALSE) { \n    df <- df[!(where1 %in% where1_exc), ]}\n  if (is.na(where1_inc[1])==FALSE) { \n    df <- df[(where1 %in% where1_inc), ]}\n  # Select where2\n  if (is.na(where2_exc[1])==FALSE) { \n    df <- df[!(where2 %in% where2_exc), ]}\n  if (is.na(where2_inc[1])==FALSE) { \n    df <- df[(where2 %in% where2_inc), ]}\n  # eliminate internal links\n  if (self==FALSE) { \n    df <- df[(where1 != where2), ]}\n  return(df)\n  \n}\n\n# Application\n\n\n######## Create complete interaction matrix ########\n\nbuild_int <- function(don = don,       # a dataframe with columns i, j , Fij\n                      i = \"where1\",\n                      j = \"where2\",\n                      Fij = \"wgt\",\n                      s1 = 5,\n                      s2 = 5,\n                      n1 = 3,\n                      n2 = 3,\n                      k = 0)\n \n# Function \n{  \n  df<-data.table(i=don[[i]],j=don[[j]],Fij=don[[Fij]])\n  #\n  int <-df[,.(Fij=sum(Fij)),.(i,j)]\n  int<-dcast(int,formula = i~j,fill = 0)\n  mat<-as.matrix(int[,-1])\n  row.names(mat)<-int$i\n  mat<-mat[apply(mat,1,sum)>=s1,apply(mat,2,sum)>=s2 ]\n  m0<-mat\n  m0[m0<k]<-0\n  m0[m0>=k]<-1\n  mat<-mat[apply(m0,1,sum)>=n1,apply(m0,2,sum)>=n2 ]\n  int<-reshape2::melt(mat)\n  names(int) <-c(\"i\",\"j\",\"Fij\")\n  return(int)\n}"
  },
  {
    "objectID": "08-Network-Analysis.html#objective",
    "href": "08-Network-Analysis.html#objective",
    "title": "10  Network analysis",
    "section": "10.1 Objective",
    "text": "10.1 Objective\nThe analysis of the different networks linking states and macroregions has been initially focused on exploratory methods but with a (too) important focus on the research of nice forms of dynamic viusalization using the VisNetworkpackage. This step was certainly important for the validation of the dictionaries and the discoveries of potential problems. But it has also limited the level of reflexion on the conceptual questions related to the definition of the network and conceptual questions. More, it has created a kind of ‘trap’ because Visnetworkis not dedicated to the computation of relevant tools for mathematical analysis of network and is not necessarily the more interesting package for visualization.\nIt appears therefore more relevant to proceed no to an opposite approach where we will use igraph package for the exploration of networks in statistical and mathematical sense i.e. computation of relevant indexes describing the whole network (e.g. fragmentation), the vertices and the edges (e.g. centrality, betweeness, …). An output of the analysis will typically be the storage of subgraphs in the format of igraph as it is very clear that all networks packages available in R use today these format as reference and can import or export it. Having stored networks in igraph format make normally easy the use of any kind of visualization tools (VisNetwork, ggraph, gephi, …).\nOther packages should also be considered in this section like backbonewhich is a high level tool of reduction of networks based on interesting conceptual hypothesis Serrano, Boguñá, and Vespignani (2009)."
  },
  {
    "objectID": "08-Network-Analysis.html#states-x-macroregion",
    "href": "08-Network-Analysis.html#states-x-macroregion",
    "title": "10  Network analysis",
    "section": "10.2 STATES x MACROREGION",
    "text": "10.2 STATES x MACROREGION\nWe start by the example of a matrix linking states and macro-region that will create a dual-mode network also called bipartite graph.\n\n10.2.1 Import hypercube\nWe choose as example the linkages between states and macroregion generated by the french media Le Figaro. The weight associated is the number of days where the link has been observed.\n\nmylang <-\"en\"\nmymedia <- c(\"fr_FRA_figaro\")\n\n#######  Preparation #############\nhc<-readRDS(\"hypercube/hc_sta_reg_day.RDS\") %>% \n  filter(where1 !=\"_no_\", where2 != \"_no_\") %>% \n  filter(is.na(when)==F, when < as.Date(\"2022-07-01\"))\n\n# Correct state table\n\nhc$where1[substr(hc$where1,1,3)==\"FRA\"]<-\"FRA\"\nhc$where1[substr(hc$where1,1,3)==\"GBR\"]<-\"GBR\"\n\n# Load table of label and choose language\nreg_def<-read.table(\"dict/Imageun_world_geo_def_V1.csv\", sep=\";\",quote = '\"', encoding = \"UTF-8\",header=T)\ntab_def<-reg_def %>% filter(lang==mylang) %>% select(code,type,label)\ntab_def<-tab_def[duplicated(tab_def$label)==F,]\n\n# Adapt some long labels\ntab_def$label[tab_def$code==\"ST_CHN\"]<-\"Chine\"\ntab_def$label[tab_def$code==\"ST_ARE\"]<-\"E.A.U.\"\ntab_def$label[tab_def$code==\"ST_COD\"]<-\"RD Congo\"\ntab_def$label[tab_def$code==\"ST_NLD\"]<-\"Pays-Bas\"\ntab_def$label[tab_def$code==\"ST_USA\"]<-\"USA\"\n\n\n# Merge regional names\nlab_reg<-tab_def %>% filter(!substr(code,1,3) %in% c(\"ST_\",\"CA_\")) %>% select(where2=code,label2=label)\nhc<-left_join(hc,lab_reg)\n\n# Merge state names\nlab_reg<-tab_def %>% filter(substr(code,1,3) %in% c(\"ST_\")) %>%\n  mutate(where1=substr(code,4,6))%>%\n  select(where1,label1=label) %>% filter(duplicated(where1)==F)\n\nhc<-left_join(hc,lab_reg)\n\n# Correct bugs\n#hc_sta_reg$label2[hc_sta_reg$label2==\"Machrek\"]<-\"Maghreb\"\n#hc_sta_reg$label2[hc_sta_reg$label2==\"Europe médiane\"]<-\"Europe centrale\"\n\n# Eliminate national links\nhc<-hc[!(substr(who,4,6)== where1),]\nhc<-hc[!(substr(who,4,6)== \"NIR\" & where1==\"GBR\"),]\n\n# Add unitary weight by day\nhc$day<-1\n\n\n\n\n# select media\nhc<-hc_filter(don = hc,\n              where1 = \"label1\",\n              where2 = \"label2\",\n                          who_inc = mymedia,\n               #           who_inc = c(\"de_DEU_frankf\", \"de_DEU_suddeu\"),\n               #            who_inc = c(\"tr_TUR_cumhur\", \"tr_TUR_yenisa\"),\n              wgt = \"day\",\n              where2_exc = c(\"_no_\"),\n              self = FALSE\n)\n\nhead(hc)\n\n>              who       when    where1            where2 wgt\n> 1: fr_FRA_figaro 2019-01-02   Somalia   United Nations    1\n> 2: fr_FRA_figaro 2019-01-02       USA            Europe   1\n> 3: fr_FRA_figaro 2019-01-07     Italy            Europe   1\n> 4: fr_FRA_figaro 2019-01-08  Thailand    European Union   1\n> 5: fr_FRA_figaro 2019-01-09 Guatemala   United Nations    1\n> 6: fr_FRA_figaro 2019-01-09     Malta Mediterranean Sea   1\n\n\nThe data indicates for each day the existence of linkages between a macroregion and a state. We decide to have a weight equal to 1, whatever the number of news that has mentionned the dyad and whatver the number of countries eventually associated to a macroregion in the same news. Of course, different choices can be made that will not be detailed here.\n\n\n10.2.2 Transform in incidence matrix\nWe can now transform the list of links into an incidence matrix where we can introduce different constraints :\n\ns1 : minimum number of days of associations of state i\ns2 : total number days of association of macroregion j\nn1 : number of links of state i with minimal value k days\nn1 : number of links of macroregion j with minimal value k days\nk : threshold of links\n\nFor example, we can decide 1. to keep only macroregions and states that has been associated during 10 days (whatever the diversity) which implies s1 = s2 = 10. 2. to keep only macroregions and states that has been associated with three different partners with a minimum level of 2 days whihc implies k = 2 and n1 = n2 =3\nNotice that the values of threshold can be asymmetric and we can decide to be more sruct for the selection of macroregion than for states or vice-versa. In the example below we can imagine that we relax the selection of macroregions to s2 = 5 and n2 = 2\n\nint<-build_int(don = hc,\n               i=\"where1\",\n               j=\"where2\",\n               Fij = \"wgt\",\n               s1 = 10,\n               s2 = 5,\n               n1 = 3,\n               n2 = 2,\n               k = 2\n               )\ntab<-dcast(int, formula = i~j, value.var = \"Fij\", fill = 0)\nmat<-as.matrix(tab[,-1])\nrow.names(mat)<-tab$i\nkable(mat)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfrica\nAfrican Union\nArctic\nAsia\nBlack Sea\nChina Sea\nCouncil of Europe\nEurope\nEuropean Union\nEurovision\nMediterranean Sea\nMiddle East\nNATO\nSahara\nSahel\nUnited Nations\n\n\n\n\nAfghanistan\n0\n0\n0\n0\n0\n0\n1\n3\n11\n0\n0\n0\n11\n0\n1\n21\n\n\nAlgeria\n1\n0\n0\n0\n0\n0\n0\n0\n3\n0\n0\n0\n0\n2\n2\n1\n\n\nBelarus\n0\n0\n0\n0\n0\n0\n2\n6\n28\n0\n0\n0\n4\n0\n0\n6\n\n\nBrazil\n0\n0\n0\n0\n0\n0\n0\n2\n2\n0\n0\n0\n0\n0\n0\n5\n\n\nChine\n2\n0\n1\n4\n0\n4\n0\n19\n31\n0\n0\n0\n3\n0\n0\n28\n\n\nCyprus\n0\n0\n0\n0\n0\n0\n0\n2\n8\n2\n4\n0\n0\n0\n0\n2\n\n\nGermany\n0\n0\n1\n0\n0\n0\n1\n18\n20\n0\n3\n0\n3\n0\n0\n6\n\n\nGreece\n0\n0\n0\n0\n0\n0\n4\n7\n14\n0\n18\n0\n6\n0\n0\n0\n\n\nIran\n0\n0\n0\n0\n0\n0\n0\n7\n11\n0\n2\n10\n1\n0\n0\n25\n\n\nIraq\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n4\n0\n0\n6\n\n\nIsrael\n0\n1\n0\n0\n0\n0\n0\n0\n7\n3\n1\n3\n0\n0\n0\n11\n\n\nItaly\n0\n0\n0\n0\n0\n0\n0\n18\n16\n1\n2\n0\n0\n0\n0\n0\n\n\nLibya\n0\n0\n0\n0\n0\n0\n0\n5\n11\n0\n6\n0\n1\n0\n0\n37\n\n\nMali\n0\n2\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n4\n9\n\n\nMorocco\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n2\n0\n0\n5\n0\n1\n\n\nPoland\n0\n0\n0\n0\n0\n0\n2\n2\n18\n0\n0\n0\n1\n0\n0\n1\n\n\nRussia\n5\n0\n3\n1\n2\n0\n9\n12\n30\n0\n1\n1\n8\n0\n2\n15\n\n\nSpain\n2\n0\n0\n0\n0\n0\n1\n8\n6\n0\n1\n0\n0\n1\n0\n0\n\n\nSudan\n2\n2\n0\n0\n0\n0\n0\n0\n5\n0\n0\n0\n0\n0\n0\n7\n\n\nSyria\n0\n0\n0\n0\n0\n0\n2\n2\n9\n0\n1\n0\n2\n0\n0\n36\n\n\nTurkey\n0\n0\n0\n0\n2\n0\n2\n16\n34\n0\n27\n0\n12\n0\n0\n2\n\n\nUkraine\n0\n0\n0\n0\n2\n0\n1\n1\n8\n1\n0\n0\n2\n0\n0\n2\n\n\nUnited Kingdom\n1\n0\n0\n0\n1\n0\n0\n19\n83\n0\n0\n0\n2\n0\n0\n7\n\n\nUSA\n1\n0\n2\n5\n2\n2\n0\n27\n37\n0\n2\n3\n3\n1\n0\n44\n\n\nVenezuela\n0\n0\n0\n0\n0\n0\n0\n4\n15\n0\n0\n0\n0\n0\n0\n20\n\n\n\n\n\n\n\n10.2.3 Import to igraph\nIt is easy to transform this matrix into igraph with the function graph_from_incidence_matrix() and some aditionnal parameters.\n\nnet<-graph_from_incidence_matrix(incidence = mat,\n                     directed = T,\n                     mode = \"in\",\n                     weighted = TRUE,\n                     add.names = \"name\")\nnet\n\n> IGRAPH a255208 DNWB 41 143 -- \n> + attr: type (v/l), name (v/c), weight (e/n)\n> + edges from a255208 (vertex names):\n>  [1] Council of Europe->Afghanistan Europe           ->Afghanistan\n>  [3] European Union   ->Afghanistan NATO             ->Afghanistan\n>  [5] Sahel            ->Afghanistan United Nations   ->Afghanistan\n>  [7] Africa           ->Algeria     European Union   ->Algeria    \n>  [9] Sahara           ->Algeria     Sahel            ->Algeria    \n> [11] United Nations   ->Algeria     Council of Europe->Belarus    \n> [13] Europe           ->Belarus     European Union   ->Belarus    \n> [15] NATO             ->Belarus     United Nations   ->Belarus    \n> + ... omitted several edges\n\nplot(net)\n\n\n\n\nThe igraph visualization is absolutely horrible but it is not a problem as it is possible at any moment to import igraph network toward other packages of visualisation.\n\nlibrary(visNetwork)\ndata <- toVisNetworkData(net)\ndata$nodes$color<-as.factor(data$nodes$type)\nlevels(data$nodes$color)<-c(\"blue\",\"red\")\ndata$nodes$size<-5\ndata$edges$width<-1+sqrt(data$edges$weight)\ndata$edges$color = \"orange\"\nvisNetwork(nodes = data$nodes, edges = data$edges,) %>% visOptions(highlightNearest = list(enabled=T, degree=list(from=1,to=1)),\n               nodesIdSelection = TRUE) \n\n\n\n\n\n\n\n\n\nSerrano, M. Ángeles, Marián Boguñá, and Alessandro Vespignani. 2009. “Extracting the Multiscale Backbone of Complex Weighted Networks.” Proceedings of the National Academy of Sciences 106 (16): 6483–88. https://doi.org/10.1073/pnas.0808904106."
  },
  {
    "objectID": "08-Network-Analysis.html#network-creation",
    "href": "08-Network-Analysis.html#network-creation",
    "title": "10  Network analysis",
    "section": "10.2 NETWORK CREATION",
    "text": "10.2 NETWORK CREATION\nWe start by the example of a matrix linking states and macro-region that will create a dual-mode network also called bipartite graph.\n\n10.2.1 Import hypercube\nWe choose as example the linkages between states and macroregion generated by the french media Le Figaro. The weight associated is the number of days where the link has been observed.\n\nmylang <-\"en\"\nmymedia <- c(\"fr_FRA_figaro\")\n\n#######  Preparation #############\nhc<-readRDS(\"hypercube/hc_sta_reg_day.RDS\") %>% \n  filter(where1 !=\"_no_\", where2 != \"_no_\") %>% \n  filter(is.na(when)==F, when < as.Date(\"2022-07-01\"))\n\n# Correct state table\n\nhc$where1[substr(hc$where1,1,3)==\"FRA\"]<-\"FRA\"\nhc$where1[substr(hc$where1,1,3)==\"GBR\"]<-\"GBR\"\n\n# Load table of label and choose language\nreg_def<-read.table(\"dict/Imageun_world_geo_def_V1.csv\", sep=\";\",quote = '\"', encoding = \"UTF-8\",header=T)\ntab_def<-reg_def %>% filter(lang==mylang) %>% select(code,type,label)\ntab_def<-tab_def[duplicated(tab_def$label)==F,]\n\n# Adapt some long labels\ntab_def$label[tab_def$code==\"ST_CHN\"]<-\"Chine\"\ntab_def$label[tab_def$code==\"ST_ARE\"]<-\"E.A.U.\"\ntab_def$label[tab_def$code==\"ST_COD\"]<-\"RD Congo\"\ntab_def$label[tab_def$code==\"ST_NLD\"]<-\"Pays-Bas\"\ntab_def$label[tab_def$code==\"ST_USA\"]<-\"USA\"\n\n\n# Merge regional names\nlab_reg<-tab_def %>% filter(!substr(code,1,3) %in% c(\"ST_\",\"CA_\")) %>% select(where2=code,label2=label)\nhc<-left_join(hc,lab_reg)\n\n# Merge state names\nlab_reg<-tab_def %>% filter(substr(code,1,3) %in% c(\"ST_\")) %>%\n  mutate(where1=substr(code,4,6))%>%\n  select(where1,label1=label) %>% filter(duplicated(where1)==F)\n\nhc<-left_join(hc,lab_reg)\n\n# Correct bugs\n#hc_sta_reg$label2[hc_sta_reg$label2==\"Machrek\"]<-\"Maghreb\"\n#hc_sta_reg$label2[hc_sta_reg$label2==\"Europe médiane\"]<-\"Europe centrale\"\n\n# Eliminate national links\nhc<-hc[!(substr(who,4,6)== where1),]\nhc<-hc[!(substr(who,4,6)== \"NIR\" & where1==\"GBR\"),]\n\n# Add unitary weight by day\nhc$day<-1\n\n\n\n\n# select media\nhc<-hc_filter(don = hc,\n              where1 = \"label1\",\n              where2 = \"label2\",\n                          who_inc = mymedia,\n               #           who_inc = c(\"de_DEU_frankf\", \"de_DEU_suddeu\"),\n               #            who_inc = c(\"tr_TUR_cumhur\", \"tr_TUR_yenisa\"),\n              wgt = \"day\",\n              where2_exc = c(\"_no_\"),\n              self = FALSE\n)\n\nhead(hc)\n\n>              who       when    where1            where2 wgt\n> 1: fr_FRA_figaro 2019-01-02   Somalia   United Nations    1\n> 2: fr_FRA_figaro 2019-01-02       USA            Europe   1\n> 3: fr_FRA_figaro 2019-01-07     Italy            Europe   1\n> 4: fr_FRA_figaro 2019-01-08  Thailand    European Union   1\n> 5: fr_FRA_figaro 2019-01-09 Guatemala   United Nations    1\n> 6: fr_FRA_figaro 2019-01-09     Malta Mediterranean Sea   1\n\n\nThe data indicates for each day the existence of linkages between a macroregion and a state. We decide to have a weight equal to 1, whatever the number of news that has mentionned the dyad and whatver the number of countries eventually associated to a macroregion in the same news. Of course, different choices can be made that will not be detailed here.\n\n\n10.2.2 Transform in incidence matrix\nWe can now transform the list of links into an incidence matrix where we can introduce different constraints :\n\ns1 : minimum number of days of associations of state i\ns2 : total number days of association of macroregion j\nn1 : number of links of state i with minimal value k days\nn1 : number of links of macroregion j with minimal value k days\nk : threshold of links\n\nFor example, we can decide 1. to keep only macroregions and states that has been associated during 10 days (whatever the diversity) which implies s1 = s2 = 10. 2. to keep only macroregions and states that has been associated with three different partners with a minimum level of 2 days whihc implies k = 2 and n1 = n2 =3\nNotice that the values of threshold can be asymmetric and we can decide to be more sruct for the selection of macroregion than for states or vice-versa. In the example below we can imagine that we relax the selection of macroregions to s2 = 5 and n2 = 2\n\nint<-build_int(don = hc,\n               i=\"where1\",\n               j=\"where2\",\n               Fij = \"wgt\",\n               s1 = 10,\n               s2 = 5,\n               n1 = 3,\n               n2 = 2,\n               k = 2\n               )\ntab<-dcast(int, formula = i~j, value.var = \"Fij\", fill = 0)\nmat<-as.matrix(tab[,-1])\nrow.names(mat)<-tab$i\nkable(mat)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfrica\nAfrican Union\nArctic\nAsia\nBlack Sea\nChina Sea\nCouncil of Europe\nEurope\nEuropean Union\nEurovision\nMediterranean Sea\nMiddle East\nNATO\nSahara\nSahel\nUnited Nations\n\n\n\n\nAfghanistan\n0\n0\n0\n0\n0\n0\n1\n3\n11\n0\n0\n0\n11\n0\n1\n21\n\n\nAlgeria\n1\n0\n0\n0\n0\n0\n0\n0\n3\n0\n0\n0\n0\n2\n2\n1\n\n\nBelarus\n0\n0\n0\n0\n0\n0\n2\n6\n28\n0\n0\n0\n4\n0\n0\n6\n\n\nBrazil\n0\n0\n0\n0\n0\n0\n0\n2\n2\n0\n0\n0\n0\n0\n0\n5\n\n\nChine\n2\n0\n1\n4\n0\n4\n0\n19\n31\n0\n0\n0\n3\n0\n0\n28\n\n\nCyprus\n0\n0\n0\n0\n0\n0\n0\n2\n8\n2\n4\n0\n0\n0\n0\n2\n\n\nGermany\n0\n0\n1\n0\n0\n0\n1\n18\n20\n0\n3\n0\n3\n0\n0\n6\n\n\nGreece\n0\n0\n0\n0\n0\n0\n4\n7\n14\n0\n18\n0\n6\n0\n0\n0\n\n\nIran\n0\n0\n0\n0\n0\n0\n0\n7\n11\n0\n2\n10\n1\n0\n0\n25\n\n\nIraq\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n4\n0\n0\n6\n\n\nIsrael\n0\n1\n0\n0\n0\n0\n0\n0\n7\n3\n1\n3\n0\n0\n0\n11\n\n\nItaly\n0\n0\n0\n0\n0\n0\n0\n18\n16\n1\n2\n0\n0\n0\n0\n0\n\n\nLibya\n0\n0\n0\n0\n0\n0\n0\n5\n11\n0\n6\n0\n1\n0\n0\n37\n\n\nMali\n0\n2\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n4\n9\n\n\nMorocco\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n2\n0\n0\n5\n0\n1\n\n\nPoland\n0\n0\n0\n0\n0\n0\n2\n2\n18\n0\n0\n0\n1\n0\n0\n1\n\n\nRussia\n5\n0\n3\n1\n2\n0\n9\n12\n30\n0\n1\n1\n8\n0\n2\n15\n\n\nSpain\n2\n0\n0\n0\n0\n0\n1\n8\n6\n0\n1\n0\n0\n1\n0\n0\n\n\nSudan\n2\n2\n0\n0\n0\n0\n0\n0\n5\n0\n0\n0\n0\n0\n0\n7\n\n\nSyria\n0\n0\n0\n0\n0\n0\n2\n2\n9\n0\n1\n0\n2\n0\n0\n36\n\n\nTurkey\n0\n0\n0\n0\n2\n0\n2\n16\n34\n0\n27\n0\n12\n0\n0\n2\n\n\nUkraine\n0\n0\n0\n0\n2\n0\n1\n1\n8\n1\n0\n0\n2\n0\n0\n2\n\n\nUnited Kingdom\n1\n0\n0\n0\n1\n0\n0\n19\n83\n0\n0\n0\n2\n0\n0\n7\n\n\nUSA\n1\n0\n2\n5\n2\n2\n0\n27\n37\n0\n2\n3\n3\n1\n0\n44\n\n\nVenezuela\n0\n0\n0\n0\n0\n0\n0\n4\n15\n0\n0\n0\n0\n0\n0\n20\n\n\n\n\n\n\n\n10.2.3 Import to igraph\nIt is easy to transform this matrix into igraph with the function graph_from_incidence_matrix() and some aditionnal parameters.\n\nnet<-graph_from_incidence_matrix(incidence = mat,\n                     directed = F,\n                     weighted = TRUE,\n                     add.names = \"name\")\nnet\n\n> IGRAPH 8d74868 UNWB 41 143 -- \n> + attr: type (v/l), name (v/c), weight (e/n)\n> + edges from 8d74868 (vertex names):\n>  [1] Afghanistan--Council of Europe Afghanistan--Europe           \n>  [3] Afghanistan--European Union    Afghanistan--NATO             \n>  [5] Afghanistan--Sahel             Afghanistan--United Nations   \n>  [7] Algeria    --Africa            Algeria    --European Union   \n>  [9] Algeria    --Sahara            Algeria    --Sahel            \n> [11] Algeria    --United Nations    Belarus    --Council of Europe\n> [13] Belarus    --Europe            Belarus    --European Union   \n> [15] Belarus    --NATO              Belarus    --United Nations   \n> + ... omitted several edges\n\nplot(net)\n\n\n\n\nThe igraph visualization is absolutely horrible but it is not a problem as it is possible at any moment to import igraph network toward other packages of visualisation.\n\nlibrary(visNetwork)\ndata <- toVisNetworkData(net)\ndata$nodes$color<-as.factor(data$nodes$type)\nlevels(data$nodes$color)<-c(\"blue\",\"red\")\ndata$nodes$size<-5\ndata$edges$width<-1+sqrt(data$edges$weight)\ndata$edges$color = \"orange\"\nvisNetwork(nodes = data$nodes, edges = data$edges,) %>% visOptions(highlightNearest = list(enabled=T, degree=list(from=1,to=1)),\n               nodesIdSelection = TRUE) \n\n\n\n\n\n\n\n10.2.4 Store network\nWe can store our network in two principle formats :\n\nas an incidence matrix\nas an igraph object\n\nWe do not decide immediately on the best solution and adopt the two formats.\n\nsaveRDS(mat,\"networks/Figaro_sta_reg_mat.RDS\")\nsaveRDS(net,\"networks/Figaro_sta_reg_net.RDS\")"
  },
  {
    "objectID": "08-Network-Analysis.html#subnetworks-analysis",
    "href": "08-Network-Analysis.html#subnetworks-analysis",
    "title": "10  Network analysis",
    "section": "10.3 SUBNETWORKS ANALYSIS",
    "text": "10.3 SUBNETWORKS ANALYSIS\nWe propose here a list of simple analysis based on the extraction of subnetworks of interest. We will use a list of simple tools based on igraph and described by Katya Ognyanova on her website :\nhttps://kateto.net/network-visualization\n\nnet <-readRDS(\"networks/Figaro_sta_reg_net.RDS\")\nplot(net, vertex.shape=\"none\", vertex.label=V(net)$name,\n     vertex.label.color=V(net)$type+1, vertex.label.font=2, \n     vertex.label.cex=.6, edge.color=\"gray70\",  edge.width=2)\n\n\n\nV(net)$name\n\n>  [1] \"Afghanistan\"       \"Algeria\"           \"Belarus\"          \n>  [4] \"Brazil\"            \"Chine\"             \"Cyprus\"           \n>  [7] \"Germany\"           \"Greece\"            \"Iran\"             \n> [10] \"Iraq\"              \"Israel\"            \"Italy\"            \n> [13] \"Libya\"             \"Mali\"              \"Morocco\"          \n> [16] \"Poland\"            \"Russia\"            \"Spain\"            \n> [19] \"Sudan\"             \"Syria\"             \"Turkey\"           \n> [22] \"Ukraine\"           \"United Kingdom\"    \"USA\"              \n> [25] \"Venezuela\"         \"Africa\"            \"African Union\"    \n> [28] \"Arctic\"            \"Asia\"              \"Black Sea\"        \n> [31] \"China Sea\"         \"Council of Europe\" \"Europe\"           \n> [34] \"European Union\"    \"Eurovision\"        \"Mediterranean Sea\"\n> [37] \"Middle East\"       \"NATO\"              \"Sahara\"           \n> [40] \"Sahel\"             \"United Nations \"\n\n\n\n10.3.1 Ego_networks\nIt is relatively easy to extract egonetworks i.e. subnetworks associated located at a given distance from a macroregion. For example, immediate neighbors are the states associated to a macroregion.\n\npar(mfrow=c(2,2),mar=c(0,0,3,0))\n\n# \"Mediterranean Sea\" = 36\negonet<-make_ego_graph(net,order=1,nodes =c(36), mode=\"all\")[[1]]\nplot(egonet, main=\"Mediterranean Sea\",\n     vertex.shape=\"none\", \n     vertex.label=substr(V(egonet)$name,1,4),\n     vertex.label.color=V(egonet)$type+1,\n     vertex.label.font=2, \n     vertex.label.cex=.6, \n     edge.color=\"gray70\", \n     edge.width=1+10*(E(egonet)$weight)/sum(E(egonet)$weight))\n\n# \"NATO\" = 38\negonet<-make_ego_graph(net,order=1,nodes =c(38), mode=\"all\")[[1]]\nplot(egonet, main=\"NATO\",\n     vertex.shape=\"none\", \n     vertex.label=substr(V(egonet)$name,1,4),\n     vertex.label.color=V(egonet)$type+1,\n     vertex.label.font=2, \n     vertex.label.cex=.6, \n     edge.color=\"gray70\", \n     edge.width=1+10*(E(egonet)$weight)/sum(E(egonet)$weight))\n\n# \"Europe\" = 33\negonet<-make_ego_graph(net,order=1,nodes =c(33), mode=\"all\")[[1]]\nplot(egonet, main=\"Europe\",\n     vertex.shape=\"none\", \n     vertex.label=substr(V(egonet)$name,1,4),\n     vertex.label.color=V(egonet)$type+1,\n     vertex.label.font=2, \n     vertex.label.cex=.6, \n     edge.color=\"gray70\", \n     edge.width=1+10*(E(egonet)$weight)/sum(E(egonet)$weight))\n\n# \"EU\" = 34\negonet<-make_ego_graph(net,order=1,nodes =c(34), mode=\"all\")[[1]]\nplot(egonet, main=\"European Union\",cex.main=0.3,\n     vertex.shape=\"none\", \n     vertex.label=substr(V(egonet)$name,1,4),\n     vertex.label.color=V(egonet)$type+1,\n     vertex.label.font=2, \n     vertex.label.cex=.6, \n     edge.color=\"gray70\", \n     edge.width=1+10*(E(egonet)$weight)/sum(E(egonet)$weight))\n\n\n\n\nWe can do the same for an higher order of contiguity. For example with a degred of 2, we can see what are the macroregions sharing links with the same states.\n\npar(mfrow=c(1,1),mar=c(0,0,3,0))\n\n# \"Mediterranean Sea\" = 36\negonet<-make_ego_graph(net,order=2,nodes =c(36), mode=\"all\")[[1]]\n\nplot(egonet, main=\"Mediterranean Sea / Order 2\",\n     vertex.shape=\"none\", \n     vertex.label=substr(V(egonet)$name,1,9),\n     vertex.label.color=V(egonet)$type+1,\n     vertex.label.font=2, \n     vertex.label.cex=.6, \n     edge.color=\"gray70\", \n     edge.width=1+10*(E(egonet)$weight)/sum(E(egonet)$weight))\n\n\n\n\n\n\n10.3.2 Macroregion comparison\nLet’s now consider another problem which is the comparison of two macroregions for which we want to examine the equivalence or difference of connexion with states. We take as example the case of EU and European Union\n\n10.3.2.1 chi-square => dual choice\nwe can start from a purely statistical approach before to move to the problem of visualization. We select the states associated to one of the unit a minimum of 5 times and we obtain a classical contingency table with two columns and as many lines as country with weight greater or equal to five.\n\nmat<-readRDS(\"networks/Figaro_sta_reg_mat.RDS\") \nmat<-mat[,c(\"Europe\",\"European Union\")]\ncolnames(mat)<-c(\"Europe\",\"EU\")\nmat<-mat[apply(mat,1,sum)>=5,]\nkable(addmargins(mat), caption = \"Contingency table\")\n\n\nContingency table\n\n\n\nEurope\nEU\nSum\n\n\n\n\nAfghanistan\n3\n11\n14\n\n\nBelarus\n6\n28\n34\n\n\nChine\n19\n31\n50\n\n\nCyprus\n2\n8\n10\n\n\nGermany\n18\n20\n38\n\n\nGreece\n7\n14\n21\n\n\nIran\n7\n11\n18\n\n\nIsrael\n0\n7\n7\n\n\nItaly\n18\n16\n34\n\n\nLibya\n5\n11\n16\n\n\nPoland\n2\n18\n20\n\n\nRussia\n12\n30\n42\n\n\nSpain\n8\n6\n14\n\n\nSudan\n0\n5\n5\n\n\nSyria\n2\n9\n11\n\n\nTurkey\n16\n34\n50\n\n\nUkraine\n1\n8\n9\n\n\nUnited Kingdom\n19\n83\n102\n\n\nUSA\n27\n37\n64\n\n\nVenezuela\n4\n15\n19\n\n\nSum\n176\n402\n578\n\n\n\n\n\nAs EU is more frequently mentionned than Europe, we observe in the majority of case that the highest probability of association of states is with EU and they are only two exceptions in the case of Spain and Italy :\n\npct<-round(100*addmargins(prop.table(addmargins(mat,1),1),2),1)\nkable(pct, caption=\"Probability of association\")\n\n\nProbability of association\n\n\n\nEurope\nEU\nSum\n\n\n\n\nAfghanistan\n21.4\n78.6\n100\n\n\nBelarus\n17.6\n82.4\n100\n\n\nChine\n38.0\n62.0\n100\n\n\nCyprus\n20.0\n80.0\n100\n\n\nGermany\n47.4\n52.6\n100\n\n\nGreece\n33.3\n66.7\n100\n\n\nIran\n38.9\n61.1\n100\n\n\nIsrael\n0.0\n100.0\n100\n\n\nItaly\n52.9\n47.1\n100\n\n\nLibya\n31.2\n68.8\n100\n\n\nPoland\n10.0\n90.0\n100\n\n\nRussia\n28.6\n71.4\n100\n\n\nSpain\n57.1\n42.9\n100\n\n\nSudan\n0.0\n100.0\n100\n\n\nSyria\n18.2\n81.8\n100\n\n\nTurkey\n32.0\n68.0\n100\n\n\nUkraine\n11.1\n88.9\n100\n\n\nUnited Kingdom\n18.6\n81.4\n100\n\n\nUSA\n42.2\n57.8\n100\n\n\nVenezuela\n21.1\n78.9\n100\n\n\nSum\n30.4\n69.6\n100\n\n\n\n\n\nAn obvious solution is to use a chi-square test on the contingency table in order to discover the most significant deviation in favour of one or the other candidates for association. The use of standardized residuals make possible to visualize the states that are more likely to be associated to Europe or to EU\n\nchi2 <-chisq.test(mat)\nchi2\n\n> \n>   Pearson's Chi-squared test\n> \n> data:  mat\n> X-squared = 47.08, df = 19, p-value = 0.0003479\n\nres<-chi2$residuals\nres<-res[order(res[,1]),]\nkable(res, caption = \"Standardized residuals\", digits=2)\n\n\nStandardized residuals\n\n\n\nEurope\nEU\n\n\n\n\nUnited Kingdom\n-2.16\n1.43\n\n\nPoland\n-1.66\n1.10\n\n\nIsrael\n-1.46\n0.97\n\n\nBelarus\n-1.35\n0.90\n\n\nSudan\n-1.23\n0.82\n\n\nUkraine\n-1.05\n0.70\n\n\nVenezuela\n-0.74\n0.49\n\n\nSyria\n-0.74\n0.49\n\n\nAfghanistan\n-0.61\n0.40\n\n\nCyprus\n-0.60\n0.40\n\n\nRussia\n-0.22\n0.15\n\n\nLibya\n0.06\n-0.04\n\n\nTurkey\n0.20\n-0.13\n\n\nGreece\n0.24\n-0.16\n\n\nIran\n0.65\n-0.43\n\n\nChine\n0.97\n-0.64\n\n\nUSA\n1.70\n-1.13\n\n\nSpain\n1.81\n-1.20\n\n\nGermany\n1.89\n-1.25\n\n\nItaly\n2.38\n-1.57\n\n\n\n\n\nThe fact to sort the table by the standardized residuals make possible to order the states by levels of affinity and suggest clearly here that U.K is significantly more associated to EU than to Europe (p < 0.05) and Italy is significantly more associate to Europe than to EU (p <0.05). But the other states are associated to standardized values belonging to [-2 ; +2] which means that we can not necessarily demonstrate a significant level of specialization. We can nevertheless try to propose a classification based on the residuals which will logically identify degree of preferental association to on of the macroregions :\n\npheatmap(mat=res, cutree_rows = 3)\n\n\n\n\nThe question however is to ask if the chi-square test is really the right solution from conceptual point of view. One of the most important issue is related to the pact that we have eliminated the alternative associations of states with other macroregion and we have in a sense “obliged” the states to choose between the two alternatives of EU and Europe.\n\n\n10.3.2.2 chi-square => dual choice + other\nLet’s just consider an alternative procedure where we keep the two competing macroregions but agregate the other possible choices in a third column.\n\nmat<-readRDS(\"networks/Figaro_sta_reg_mat.RDS\") \nmat1<-mat[,c(8,9)]\nmat2<-apply(mat[,-c(8,9)],1,sum)\nmat<-cbind(mat1,mat2)\ncolnames(mat)<-c(\"Europe\",\"EU\",\"Other\")\nmat<-mat[apply(mat,1,sum)>=5,]\nkable(addmargins(mat), caption = \"Contingency table\")\n\n\nContingency table\n\n\n\nEurope\nEU\nOther\nSum\n\n\n\n\nAfghanistan\n3\n11\n34\n48\n\n\nAlgeria\n0\n3\n6\n9\n\n\nBelarus\n6\n28\n12\n46\n\n\nBrazil\n2\n2\n5\n9\n\n\nChine\n19\n31\n42\n92\n\n\nCyprus\n2\n8\n8\n18\n\n\nGermany\n18\n20\n14\n52\n\n\nGreece\n7\n14\n28\n49\n\n\nIran\n7\n11\n38\n56\n\n\nIraq\n0\n0\n10\n10\n\n\nIsrael\n0\n7\n19\n26\n\n\nItaly\n18\n16\n3\n37\n\n\nLibya\n5\n11\n44\n60\n\n\nMali\n0\n1\n15\n16\n\n\nMorocco\n2\n0\n8\n10\n\n\nPoland\n2\n18\n4\n24\n\n\nRussia\n12\n30\n47\n89\n\n\nSpain\n8\n6\n5\n19\n\n\nSudan\n0\n5\n11\n16\n\n\nSyria\n2\n9\n41\n52\n\n\nTurkey\n16\n34\n45\n95\n\n\nUkraine\n1\n8\n8\n17\n\n\nUnited Kingdom\n19\n83\n11\n113\n\n\nUSA\n27\n37\n65\n129\n\n\nVenezuela\n4\n15\n20\n39\n\n\nSum\n180\n408\n543\n1131\n\n\n\n\n\nWith the new contingency table, we can introduce some countries that was previously eliminated because of non sufficient sample size in our dual selection like Iraq. But we notice also that new informations has been added and the probability for a country is defined now in a completely different way as we can see on table below :\n\npct<-round(100*addmargins(prop.table(addmargins(mat,1),1),2),1)\nkable(pct, caption=\"Probability of association\")\n\n\nProbability of association\n\n\n\nEurope\nEU\nOther\nSum\n\n\n\n\nAfghanistan\n6.2\n22.9\n70.8\n100\n\n\nAlgeria\n0.0\n33.3\n66.7\n100\n\n\nBelarus\n13.0\n60.9\n26.1\n100\n\n\nBrazil\n22.2\n22.2\n55.6\n100\n\n\nChine\n20.7\n33.7\n45.7\n100\n\n\nCyprus\n11.1\n44.4\n44.4\n100\n\n\nGermany\n34.6\n38.5\n26.9\n100\n\n\nGreece\n14.3\n28.6\n57.1\n100\n\n\nIran\n12.5\n19.6\n67.9\n100\n\n\nIraq\n0.0\n0.0\n100.0\n100\n\n\nIsrael\n0.0\n26.9\n73.1\n100\n\n\nItaly\n48.6\n43.2\n8.1\n100\n\n\nLibya\n8.3\n18.3\n73.3\n100\n\n\nMali\n0.0\n6.2\n93.8\n100\n\n\nMorocco\n20.0\n0.0\n80.0\n100\n\n\nPoland\n8.3\n75.0\n16.7\n100\n\n\nRussia\n13.5\n33.7\n52.8\n100\n\n\nSpain\n42.1\n31.6\n26.3\n100\n\n\nSudan\n0.0\n31.2\n68.8\n100\n\n\nSyria\n3.8\n17.3\n78.8\n100\n\n\nTurkey\n16.8\n35.8\n47.4\n100\n\n\nUkraine\n5.9\n47.1\n47.1\n100\n\n\nUnited Kingdom\n16.8\n73.5\n9.7\n100\n\n\nUSA\n20.9\n28.7\n50.4\n100\n\n\nVenezuela\n10.3\n38.5\n51.3\n100\n\n\nSum\n15.9\n36.1\n48.0\n100\n\n\n\n\n\nOur interpretation of the results is modified because we are now obliged to ask our question of preferences in two steps :\n\n\n“Is the country mainly associated to one of the two selected macroregions ?”: Looking at the probability of “Other” we can cleary say that Syria is mainly associated to other macroregions (78.8 %) and the fact that EU is more frequently mentionned than Europe is not an information of major interest. On the contrary, Italy is associated to “Other” in less than 8.1% of case and the fact that Europe is a bit more mentionned than EU is one more time a detail.\n\n\n“What is the most likely choice between EU and Europe when one of the two macroregions is mentionned ?” : The question that we answered before is now a conditional probability i.e. a question that make sense only if we control the role of the “other” choices and are ready to neglect it.\n\n\nThe effect of the addition of the other is much more clear when we compute the new distribution of residuals :\n\nchi2 <-chisq.test(mat)\nchi2\n\n> \n>   Pearson's Chi-squared test\n> \n> data:  mat\n> X-squared = 282.97, df = 48, p-value < 2.2e-16\n\nres<-chi2$residuals\nres<-res[order(res[,3]),]\nkable(res, caption = \"Standardized residuals\", digits=2)\n\n\nStandardized residuals\n\n\n\nEurope\nEU\nOther\n\n\n\n\nUnited Kingdom\n0.24\n6.62\n-5.87\n\n\nItaly\n4.99\n0.73\n-3.50\n\n\nPoland\n-0.93\n3.17\n-2.22\n\n\nGermany\n3.38\n0.29\n-2.19\n\n\nBelarus\n-0.49\n2.80\n-2.15\n\n\nSpain\n2.86\n-0.33\n-1.36\n\n\nChine\n1.14\n-0.38\n-0.33\n\n\nCyprus\n-0.51\n0.59\n-0.22\n\n\nTurkey\n0.23\n-0.05\n-0.09\n\n\nUkraine\n-1.04\n0.75\n-0.06\n\n\nVenezuela\n-0.89\n0.25\n0.29\n\n\nBrazil\n0.47\n-0.69\n0.33\n\n\nUSA\n1.43\n-1.40\n0.39\n\n\nRussia\n-0.58\n-0.37\n0.65\n\n\nAlgeria\n-1.20\n-0.14\n0.81\n\n\nGreece\n-0.29\n-0.87\n0.92\n\n\nSudan\n-1.60\n-0.32\n1.20\n\n\nMorocco\n0.32\n-1.90\n1.46\n\n\nIsrael\n-2.03\n-0.78\n1.84\n\n\nIran\n-0.64\n-2.05\n2.14\n\n\nAfghanistan\n-1.68\n-1.52\n2.28\n\n\nIraq\n-1.26\n-1.90\n2.37\n\n\nMali\n-1.60\n-1.99\n2.64\n\n\nLibya\n-1.47\n-2.29\n2.83\n\n\nSyria\n-2.18\n-2.25\n3.21\n\n\n\n\n\nLooking at the distribution of standardized residuals located outside the confidence interval [-2,2] we observe a much greater diversity of situations because of the introduction of the “other” possibilities :\n\nUnited Kingdom : this states remains very significantly associated to EU but much more than in the dual model (t=6.62, p < 0.000) because it is significantly less associated to the “Other” macroregions (t= -5.87, p <0.001) and is independent as regard to Europe (t=0.24 p>0.10). The right conclusion is therefore not to say that UK is more associated to EU than to Europe but rather that UK is more associated to EU than to other macroregions.\nGermany and Italy : this country present the same situation but with a significant association with Europe as compare to other macroregions and a positive but not significant association with EU. This two country are therefore clear members of “EUrope” but more freqhently associated to “Europe”.\nIran is the case of a country that is clearly more associated to “other” macroregions rather than EU or Europe (t=2.14, p < 0.05). But the low level of association is significant for EU (t=-2.05, p < 0.05) but not for Europe. In other words, the media can eventually associate Iran to “Europe” but certainly not to “EU”.\nSyria is the case of a country that is significantly less associated to both EU and Europe than expected by a random model and is significantly more associated to other macroregions. It is out of “EUrope” …\n\n\npheatmap(mat=res, cutree_rows = 7)\n\n\n\n\n\n\n\n\nSerrano, M. Ángeles, Marián Boguñá, and Alessandro Vespignani. 2009. “Extracting the Multiscale Backbone of Complex Weighted Networks.” Proceedings of the National Academy of Sciences 106 (16): 6483–88. https://doi.org/10.1073/pnas.0808904106."
  }
]